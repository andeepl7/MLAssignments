{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, precision_score, recall_score, f1_score, accuracy_score,classification_report\n",
    "from sklearn.model_selection import cross_val_score, cross_val_predict\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Addthis</th>\n",
       "      <th>Bebo</th>\n",
       "      <th>Blogcatalog</th>\n",
       "      <th>Blogger</th>\n",
       "      <th>Buddymedia</th>\n",
       "      <th>Cnet</th>\n",
       "      <th>Conduit</th>\n",
       "      <th>Customerlobby</th>\n",
       "      <th>Delicious</th>\n",
       "      <th>Digg</th>\n",
       "      <th>...</th>\n",
       "      <th>Vimeo</th>\n",
       "      <th>Vocus</th>\n",
       "      <th>Wetpaint</th>\n",
       "      <th>Wordpress</th>\n",
       "      <th>Xanga</th>\n",
       "      <th>Yelp</th>\n",
       "      <th>Yfrog</th>\n",
       "      <th>Youtube</th>\n",
       "      <th>Yuku</th>\n",
       "      <th>Click</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>dmp923122274</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dmp458034174</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dmp364043571</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dmp461339655</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dmp549691332</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 82 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              Addthis  Bebo  Blogcatalog  Blogger  Buddymedia  Cnet  Conduit  \\\n",
       "dmp923122274        0     0            2        0           0     3        6   \n",
       "dmp458034174        0     3            0        0           0     0        1   \n",
       "dmp364043571        0     2            0        0           0     0        0   \n",
       "dmp461339655        0     0            0        0           0     0        0   \n",
       "dmp549691332        0     0            0        0           0     5        7   \n",
       "\n",
       "              Customerlobby  Delicious  Digg  ... Vimeo  Vocus  Wetpaint  \\\n",
       "dmp923122274              0          0     0  ...     0      0         0   \n",
       "dmp458034174              0          0     0  ...     0      0         0   \n",
       "dmp364043571              0          2     0  ...     0      0         0   \n",
       "dmp461339655              0          0     0  ...     0      0         0   \n",
       "dmp549691332              0          0     5  ...     0      0         1   \n",
       "\n",
       "              Wordpress  Xanga  Yelp  Yfrog  Youtube  Yuku  Click  \n",
       "dmp923122274          4      0     0      1        0     1      0  \n",
       "dmp458034174         12      0     2      2       12     0      0  \n",
       "dmp364043571         11      0     0      0        0     0      0  \n",
       "dmp461339655          6      0     0      0       22     0      0  \n",
       "dmp549691332          0      0     0      1        0     0      0  \n",
       "\n",
       "[5 rows x 82 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Importing the database\n",
    "df = pd.read_csv(\"data.csv\", index_col=0)\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 10000 entries, dmp923122274 to dmp521609268\n",
      "Data columns (total 82 columns):\n",
      " #   Column         Non-Null Count  Dtype \n",
      "---  ------         --------------  ----- \n",
      " 0   Addthis        10000 non-null  int64 \n",
      " 1   Bebo           10000 non-null  int64 \n",
      " 2   Blogcatalog    10000 non-null  int64 \n",
      " 3   Blogger        10000 non-null  int64 \n",
      " 4   Buddymedia     10000 non-null  int64 \n",
      " 5   Cnet           10000 non-null  int64 \n",
      " 6   Conduit        10000 non-null  int64 \n",
      " 7   Customerlobby  10000 non-null  int64 \n",
      " 8   Delicious      10000 non-null  int64 \n",
      " 9   Digg           10000 non-null  int64 \n",
      " 10  Diigo          10000 non-null  object\n",
      " 11  Docs           10000 non-null  int64 \n",
      " 12  Docstoc        10000 non-null  int64 \n",
      " 13  Download       10000 non-null  int64 \n",
      " 14  Dropbox        10000 non-null  int64 \n",
      " 15  Drupal         10000 non-null  int64 \n",
      " 16  Epinions       10000 non-null  int64 \n",
      " 17  Evernote       10000 non-null  int64 \n",
      " 18  Facebook       10000 non-null  int64 \n",
      " 19  Faves          10000 non-null  int64 \n",
      " 20  Feedburner     10000 non-null  int64 \n",
      " 21  Flickr         10000 non-null  int64 \n",
      " 22  Foursquare     10000 non-null  int64 \n",
      " 23  Friendfeed     10000 non-null  int64 \n",
      " 24  Hootsuite      10000 non-null  int64 \n",
      " 25  Joomla         10000 non-null  int64 \n",
      " 26  Jumptags       10000 non-null  int64 \n",
      " 27  Kaboodle       10000 non-null  int64 \n",
      " 28  Kickapps       10000 non-null  int64 \n",
      " 29  Linkedin       10000 non-null  int64 \n",
      " 30  Lithium        10000 non-null  int64 \n",
      " 31  Livejournal    10000 non-null  int64 \n",
      " 32  Mashable       10000 non-null  int64 \n",
      " 33  Meetup         10000 non-null  int64 \n",
      " 34  Metacafe       10000 non-null  int64 \n",
      " 35  Mixx           10000 non-null  int64 \n",
      " 36  Mouthshut      10000 non-null  int64 \n",
      " 37  Multiply       10000 non-null  int64 \n",
      " 38  Mybloglog      10000 non-null  int64 \n",
      " 39  Myspace        10000 non-null  int64 \n",
      " 40  Netvibes       10000 non-null  int64 \n",
      " 41  Newsvine       10000 non-null  int64 \n",
      " 42  Ning           10000 non-null  int64 \n",
      " 43  Orkut          10000 non-null  int64 \n",
      " 44  Photobucket    10000 non-null  int64 \n",
      " 45  Ping           10000 non-null  int64 \n",
      " 46  Pinterest      10000 non-null  int64 \n",
      " 47  Plaxo          10000 non-null  int64 \n",
      " 48  Plurk          10000 non-null  int64 \n",
      " 49  Posterous      10000 non-null  int64 \n",
      " 50  Propeller      10000 non-null  int64 \n",
      " 51  Radian6        10000 non-null  int64 \n",
      " 52  Reddit         10000 non-null  int64 \n",
      " 53  Screencast     10000 non-null  int64 \n",
      " 54  Scribd         10000 non-null  int64 \n",
      " 55  Sharethis      10000 non-null  int64 \n",
      " 56  Slashdot       10000 non-null  int64 \n",
      " 57  Sliderocket    10000 non-null  int64 \n",
      " 58  Slideshare     10000 non-null  int64 \n",
      " 59  Squidoo        10000 non-null  int64 \n",
      " 60  Startaid       10000 non-null  int64 \n",
      " 61  Stumbleupon    10000 non-null  int64 \n",
      " 62  Sysomos        10000 non-null  int64 \n",
      " 63  Technorati     10000 non-null  int64 \n",
      " 64  Thisnext       10000 non-null  int64 \n",
      " 65  Tumblr         10000 non-null  int64 \n",
      " 66  Tweetdeck      10000 non-null  int64 \n",
      " 67  Twine          10000 non-null  int64 \n",
      " 68  Twitter        10000 non-null  int64 \n",
      " 69  Typepad        10000 non-null  int64 \n",
      " 70  Ubertwitter    10000 non-null  int64 \n",
      " 71  Viadeo         10000 non-null  int64 \n",
      " 72  Vimeo          10000 non-null  int64 \n",
      " 73  Vocus          10000 non-null  int64 \n",
      " 74  Wetpaint       10000 non-null  int64 \n",
      " 75  Wordpress      10000 non-null  int64 \n",
      " 76  Xanga          10000 non-null  int64 \n",
      " 77  Yelp           10000 non-null  int64 \n",
      " 78  Yfrog          10000 non-null  int64 \n",
      " 79  Youtube        10000 non-null  int64 \n",
      " 80  Yuku           10000 non-null  int64 \n",
      " 81  Click          10000 non-null  int64 \n",
      "dtypes: int64(81), object(1)\n",
      "memory usage: 6.3+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()\n",
    "#Diigo: object "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                         8842\n",
       "Error: value not found     642\n",
       "1                          332\n",
       "2                          183\n",
       "3                            1\n",
       "Name: Diigo, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"Diigo\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace errors with NaN\n",
    "df.loc[df[\"Diigo\"]==\"Error: value not found\",\"Diigo\"] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert type\n",
    "df[\"Diigo\"] = df[\"Diigo\"].astype(\"float64\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Addthis</th>\n",
       "      <th>Bebo</th>\n",
       "      <th>Blogcatalog</th>\n",
       "      <th>Blogger</th>\n",
       "      <th>Buddymedia</th>\n",
       "      <th>Cnet</th>\n",
       "      <th>Conduit</th>\n",
       "      <th>Customerlobby</th>\n",
       "      <th>Delicious</th>\n",
       "      <th>Digg</th>\n",
       "      <th>...</th>\n",
       "      <th>Vimeo</th>\n",
       "      <th>Vocus</th>\n",
       "      <th>Wetpaint</th>\n",
       "      <th>Wordpress</th>\n",
       "      <th>Xanga</th>\n",
       "      <th>Yelp</th>\n",
       "      <th>Yfrog</th>\n",
       "      <th>Youtube</th>\n",
       "      <th>Yuku</th>\n",
       "      <th>Click</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>10000.00000</td>\n",
       "      <td>10000.00000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>10000.00000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.42250</td>\n",
       "      <td>0.78130</td>\n",
       "      <td>0.568100</td>\n",
       "      <td>2.823700</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.950400</td>\n",
       "      <td>2.142100</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>0.393100</td>\n",
       "      <td>1.012700</td>\n",
       "      <td>...</td>\n",
       "      <td>0.41190</td>\n",
       "      <td>0.040200</td>\n",
       "      <td>0.293600</td>\n",
       "      <td>2.176900</td>\n",
       "      <td>0.459500</td>\n",
       "      <td>0.602200</td>\n",
       "      <td>0.380800</td>\n",
       "      <td>6.040600</td>\n",
       "      <td>0.206600</td>\n",
       "      <td>0.123400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.01405</td>\n",
       "      <td>1.48899</td>\n",
       "      <td>1.197709</td>\n",
       "      <td>5.571438</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.937619</td>\n",
       "      <td>3.293993</td>\n",
       "      <td>0.014141</td>\n",
       "      <td>0.811319</td>\n",
       "      <td>2.266021</td>\n",
       "      <td>...</td>\n",
       "      <td>1.00436</td>\n",
       "      <td>0.196438</td>\n",
       "      <td>0.612402</td>\n",
       "      <td>3.691879</td>\n",
       "      <td>0.982169</td>\n",
       "      <td>1.194696</td>\n",
       "      <td>0.755413</td>\n",
       "      <td>7.892679</td>\n",
       "      <td>0.588856</td>\n",
       "      <td>0.328912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.00000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>6.00000</td>\n",
       "      <td>8.00000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>7.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>36.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 82 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Addthis         Bebo   Blogcatalog       Blogger  Buddymedia  \\\n",
       "count  10000.00000  10000.00000  10000.000000  10000.000000     10000.0   \n",
       "mean       0.42250      0.78130      0.568100      2.823700         0.0   \n",
       "std        1.01405      1.48899      1.197709      5.571438         0.0   \n",
       "min        0.00000      0.00000      0.000000      0.000000         0.0   \n",
       "25%        0.00000      0.00000      0.000000      0.000000         0.0   \n",
       "50%        0.00000      0.00000      0.000000      0.000000         0.0   \n",
       "75%        0.00000      1.00000      0.000000      0.000000         0.0   \n",
       "max        6.00000      8.00000      7.000000     28.000000         0.0   \n",
       "\n",
       "               Cnet       Conduit  Customerlobby     Delicious          Digg  \\\n",
       "count  10000.000000  10000.000000   10000.000000  10000.000000  10000.000000   \n",
       "mean       1.950400      2.142100       0.000200      0.393100      1.012700   \n",
       "std        2.937619      3.293993       0.014141      0.811319      2.266021   \n",
       "min        0.000000      0.000000       0.000000      0.000000      0.000000   \n",
       "25%        0.000000      0.000000       0.000000      0.000000      0.000000   \n",
       "50%        0.000000      0.000000       0.000000      0.000000      0.000000   \n",
       "75%        4.000000      4.000000       0.000000      0.000000      0.000000   \n",
       "max       15.000000     16.000000       1.000000      4.000000     13.000000   \n",
       "\n",
       "       ...        Vimeo         Vocus      Wetpaint     Wordpress  \\\n",
       "count  ...  10000.00000  10000.000000  10000.000000  10000.000000   \n",
       "mean   ...      0.41190      0.040200      0.293600      2.176900   \n",
       "std    ...      1.00436      0.196438      0.612402      3.691879   \n",
       "min    ...      0.00000      0.000000      0.000000      0.000000   \n",
       "25%    ...      0.00000      0.000000      0.000000      0.000000   \n",
       "50%    ...      0.00000      0.000000      0.000000      0.000000   \n",
       "75%    ...      0.00000      0.000000      0.000000      4.000000   \n",
       "max    ...      7.00000      1.000000      3.000000     19.000000   \n",
       "\n",
       "              Xanga          Yelp         Yfrog       Youtube          Yuku  \\\n",
       "count  10000.000000  10000.000000  10000.000000  10000.000000  10000.000000   \n",
       "mean       0.459500      0.602200      0.380800      6.040600      0.206600   \n",
       "std        0.982169      1.194696      0.755413      7.892679      0.588856   \n",
       "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "50%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "75%        0.000000      0.000000      0.000000     12.000000      0.000000   \n",
       "max        5.000000      7.000000      4.000000     36.000000      4.000000   \n",
       "\n",
       "              Click  \n",
       "count  10000.000000  \n",
       "mean       0.123400  \n",
       "std        0.328912  \n",
       "min        0.000000  \n",
       "25%        0.000000  \n",
       "50%        0.000000  \n",
       "75%        0.000000  \n",
       "max        1.000000  \n",
       "\n",
       "[8 rows x 82 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Exploring data \n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in df:\n",
    "    if df[column].apply(type).eq(str).any():\n",
    "        print(\"The\" , column, \"contains strings\")\n",
    "    if df[column].any() < 0:\n",
    "        print(\"The\" , column, \"contains negative values.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Newsvine', 'max: 96372367637']\n"
     ]
    }
   ],
   "source": [
    "#check for outliers below 0 and above 1000 clicks\n",
    "\n",
    "outliers = []\n",
    "\n",
    "for c in df.columns:\n",
    "    if df[c].max()>=1000:\n",
    "        outliers.append(c)\n",
    "        outliers.append(\"max: \" + str(df[c].max()))\n",
    "    if df[c].min()<0:\n",
    "        outliers.append(c)\n",
    "        outliers.append(\"min: \" + str(df[c].min()))\n",
    "\n",
    "print(outliers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.0\n"
     ]
    }
   ],
   "source": [
    "#replace outlier\n",
    "df.loc[df[\"Newsvine\"]==df[\"Newsvine\"].max(),\"Newsvine\"] = np.nan\n",
    "print(df[\"Newsvine\"].max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Addthis        0\n",
       "Bebo           0\n",
       "Blogcatalog    0\n",
       "Blogger        0\n",
       "Buddymedia     0\n",
       "              ..\n",
       "Yelp           0\n",
       "Yfrog          0\n",
       "Youtube        0\n",
       "Yuku           0\n",
       "Click          0\n",
       "Length: 82, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Diigo': 642, 'Newsvine': 1}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nan_col = {}\n",
    "for c in df.columns:\n",
    "    if df[c].isna().sum()>0:\n",
    "        nan_col[c]=df[c].isna().sum()\n",
    "nan_col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(\"Diigo\", axis=1)\n",
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Addthis</th>\n",
       "      <th>Bebo</th>\n",
       "      <th>Blogcatalog</th>\n",
       "      <th>Blogger</th>\n",
       "      <th>Buddymedia</th>\n",
       "      <th>Cnet</th>\n",
       "      <th>Conduit</th>\n",
       "      <th>Customerlobby</th>\n",
       "      <th>Delicious</th>\n",
       "      <th>Digg</th>\n",
       "      <th>...</th>\n",
       "      <th>Vimeo</th>\n",
       "      <th>Vocus</th>\n",
       "      <th>Wetpaint</th>\n",
       "      <th>Wordpress</th>\n",
       "      <th>Xanga</th>\n",
       "      <th>Yelp</th>\n",
       "      <th>Yfrog</th>\n",
       "      <th>Youtube</th>\n",
       "      <th>Yuku</th>\n",
       "      <th>Click</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>dmp923122274</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dmp458034174</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dmp364043571</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dmp461339655</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dmp549691332</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dmp526137646</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dmp229602119</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dmp432025886</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dmp978420782</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dmp319040990</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 81 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              Addthis  Bebo  Blogcatalog  Blogger  Buddymedia  Cnet  Conduit  \\\n",
       "dmp923122274     True  True         True     True        True  True     True   \n",
       "dmp458034174     True  True         True     True        True  True     True   \n",
       "dmp364043571     True  True         True     True        True  True     True   \n",
       "dmp461339655     True  True         True     True        True  True     True   \n",
       "dmp549691332     True  True         True     True        True  True     True   \n",
       "dmp526137646     True  True         True     True        True  True     True   \n",
       "dmp229602119     True  True         True     True        True  True     True   \n",
       "dmp432025886     True  True         True     True        True  True     True   \n",
       "dmp978420782     True  True         True     True        True  True     True   \n",
       "dmp319040990     True  True         True     True        True  True     True   \n",
       "\n",
       "              Customerlobby  Delicious  Digg  ...  Vimeo  Vocus  Wetpaint  \\\n",
       "dmp923122274           True       True  True  ...   True   True      True   \n",
       "dmp458034174           True       True  True  ...   True   True      True   \n",
       "dmp364043571           True       True  True  ...   True   True      True   \n",
       "dmp461339655           True       True  True  ...   True   True      True   \n",
       "dmp549691332           True       True  True  ...   True   True      True   \n",
       "dmp526137646           True       True  True  ...   True   True      True   \n",
       "dmp229602119           True       True  True  ...   True   True      True   \n",
       "dmp432025886           True       True  True  ...   True   True      True   \n",
       "dmp978420782           True       True  True  ...   True   True      True   \n",
       "dmp319040990           True       True  True  ...   True   True      True   \n",
       "\n",
       "              Wordpress  Xanga  Yelp  Yfrog  Youtube  Yuku  Click  \n",
       "dmp923122274       True   True  True   True     True  True   True  \n",
       "dmp458034174       True   True  True   True     True  True   True  \n",
       "dmp364043571       True   True  True   True     True  True   True  \n",
       "dmp461339655       True   True  True   True     True  True   True  \n",
       "dmp549691332       True   True  True   True     True  True   True  \n",
       "dmp526137646       True   True  True   True     True  True   True  \n",
       "dmp229602119       True   True  True   True     True  True   True  \n",
       "dmp432025886       True   True  True   True     True  True   True  \n",
       "dmp978420782       True   True  True   True     True  True   True  \n",
       "dmp319040990       True   True  True   True     True  True   True  \n",
       "\n",
       "[10 rows x 81 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Exploring if another value is different to numbers in the Data. \n",
    "result = df.applymap(np.isreal)\n",
    "result.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Addthis        int64\n",
       "Bebo           int64\n",
       "Blogcatalog    int64\n",
       "Blogger        int64\n",
       "Buddymedia     int64\n",
       "               ...  \n",
       "Yelp           int64\n",
       "Yfrog          int64\n",
       "Youtube        int64\n",
       "Yuku           int64\n",
       "Click          int64\n",
       "Length: 81, dtype: object"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Checking the datatypes\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Addthis</th>\n",
       "      <th>Bebo</th>\n",
       "      <th>Blogcatalog</th>\n",
       "      <th>Blogger</th>\n",
       "      <th>Buddymedia</th>\n",
       "      <th>Cnet</th>\n",
       "      <th>Conduit</th>\n",
       "      <th>Customerlobby</th>\n",
       "      <th>Delicious</th>\n",
       "      <th>Digg</th>\n",
       "      <th>...</th>\n",
       "      <th>Vimeo</th>\n",
       "      <th>Vocus</th>\n",
       "      <th>Wetpaint</th>\n",
       "      <th>Wordpress</th>\n",
       "      <th>Xanga</th>\n",
       "      <th>Yelp</th>\n",
       "      <th>Yfrog</th>\n",
       "      <th>Youtube</th>\n",
       "      <th>Yuku</th>\n",
       "      <th>Click</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>dmp923122274</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dmp458034174</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dmp364043571</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dmp461339655</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dmp549691332</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 81 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              Addthis  Bebo  Blogcatalog  Blogger  Buddymedia  Cnet  Conduit  \\\n",
       "dmp923122274        0     0            2        0           0     3        6   \n",
       "dmp458034174        0     3            0        0           0     0        1   \n",
       "dmp364043571        0     2            0        0           0     0        0   \n",
       "dmp461339655        0     0            0        0           0     0        0   \n",
       "dmp549691332        0     0            0        0           0     5        7   \n",
       "\n",
       "              Customerlobby  Delicious  Digg  ...  Vimeo  Vocus  Wetpaint  \\\n",
       "dmp923122274              0          0     0  ...      0      0         0   \n",
       "dmp458034174              0          0     0  ...      0      0         0   \n",
       "dmp364043571              0          2     0  ...      0      0         0   \n",
       "dmp461339655              0          0     0  ...      0      0         0   \n",
       "dmp549691332              0          0     5  ...      0      0         1   \n",
       "\n",
       "              Wordpress  Xanga  Yelp  Yfrog  Youtube  Yuku  Click  \n",
       "dmp923122274          4      0     0      1        0     1      0  \n",
       "dmp458034174         12      0     2      2       12     0      0  \n",
       "dmp364043571         11      0     0      0        0     0      0  \n",
       "dmp461339655          6      0     0      0       22     0      0  \n",
       "dmp549691332          0      0     0      1        0     0      0  \n",
       "\n",
       "[5 rows x 81 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Checking point\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12.34"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Insights of the data.\n",
    "ax = sns.countplot(x ='Click', data = df)\n",
    "abs_values = df['Click'].value_counts(ascending=False).values\n",
    "ax.bar_label(container=ax.containers[0], labels=abs_values)\n",
    "\n",
    "round(df[\"Click\"].sum()/df[\"Click\"].count() * 100, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Selecting the columns for features X and target Y\n",
    "y = df['Click']\n",
    "X = df.drop(\"Click\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating a Train set (80%) and Test set (20%)\n",
    "X_train, X_test , y_train, y_test = train_test_split(X,y, test_size=0.20, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implement SVM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scaling\n",
    "X_train = StandardScaler().fit_transform(X_train)\n",
    "X_test = StandardScaler().fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\"C\": [0.1, 1, 10, 100, 1000],  \n",
    "              \"gamma\": [1, 0.1, 0.01, 0.001, 0.0001], \n",
    "              \"kernel\": [\"rbf\"]} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "SVM Model Performance:\n",
      "Confusion Matrix:\n",
      "[[1747   23]\n",
      " [  58  172]]\n",
      "Precision: 0.882051282051282\n",
      "Recall: 0.7478260869565218\n",
      "F1 Score: 0.8094117647058823\n",
      "Accuracy: 0.9595\n"
     ]
    }
   ],
   "source": [
    "#SVM model classification\n",
    "svm_model = SVC()\n",
    "\n",
    "svm_model.fit(X_train, y_train)\n",
    "y_pred_svm = svm_model.predict(X_test)\n",
    "print(\"\\nSVM Model Performance:\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred_svm))\n",
    "print(\"Precision:\", precision_score(y_test, y_pred_svm, zero_division= 1))\n",
    "print(\"Recall:\", recall_score(y_test, y_pred_svm))\n",
    "print(\"F1 Score:\", f1_score(y_test, y_pred_svm))\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred_svm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_svm = GridSearchCV(estimator=svm_model, \n",
    "                        param_grid=param_grid, \n",
    "                        refit=True, verbose=3, \n",
    "                        cv=5, \n",
    "                        return_train_score=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 25 candidates, totalling 125 fits\n",
      "[CV 1/5] END C=0.1, gamma=1, kernel=rbf;, score=(train=0.875, test=0.874) total time=   5.9s\n",
      "[CV 2/5] END C=0.1, gamma=1, kernel=rbf;, score=(train=0.875, test=0.874) total time=   5.5s\n",
      "[CV 3/5] END C=0.1, gamma=1, kernel=rbf;, score=(train=0.875, test=0.874) total time=   5.4s\n",
      "[CV 4/5] END C=0.1, gamma=1, kernel=rbf;, score=(train=0.875, test=0.874) total time=   5.0s\n",
      "[CV 5/5] END C=0.1, gamma=1, kernel=rbf;, score=(train=0.874, test=0.875) total time=   5.6s\n",
      "[CV 1/5] END C=0.1, gamma=0.1, kernel=rbf;, score=(train=0.875, test=0.874) total time=   5.2s\n",
      "[CV 2/5] END C=0.1, gamma=0.1, kernel=rbf;, score=(train=0.875, test=0.874) total time=   5.4s\n",
      "[CV 3/5] END C=0.1, gamma=0.1, kernel=rbf;, score=(train=0.875, test=0.874) total time=   5.4s\n",
      "[CV 4/5] END C=0.1, gamma=0.1, kernel=rbf;, score=(train=0.875, test=0.874) total time=   5.1s\n",
      "[CV 5/5] END C=0.1, gamma=0.1, kernel=rbf;, score=(train=0.874, test=0.875) total time=   5.5s\n",
      "[CV 1/5] END C=0.1, gamma=0.01, kernel=rbf;, score=(train=0.875, test=0.874) total time=   1.3s\n",
      "[CV 2/5] END C=0.1, gamma=0.01, kernel=rbf;, score=(train=0.875, test=0.874) total time=   1.3s\n",
      "[CV 3/5] END C=0.1, gamma=0.01, kernel=rbf;, score=(train=0.875, test=0.874) total time=   1.6s\n",
      "[CV 4/5] END C=0.1, gamma=0.01, kernel=rbf;, score=(train=0.875, test=0.874) total time=   1.6s\n",
      "[CV 5/5] END C=0.1, gamma=0.01, kernel=rbf;, score=(train=0.874, test=0.875) total time=   1.3s\n",
      "[CV 1/5] END C=0.1, gamma=0.001, kernel=rbf;, score=(train=0.875, test=0.874) total time=   1.4s\n",
      "[CV 2/5] END C=0.1, gamma=0.001, kernel=rbf;, score=(train=0.875, test=0.874) total time=   1.1s\n",
      "[CV 3/5] END C=0.1, gamma=0.001, kernel=rbf;, score=(train=0.875, test=0.874) total time=   1.3s\n",
      "[CV 4/5] END C=0.1, gamma=0.001, kernel=rbf;, score=(train=0.875, test=0.874) total time=   1.3s\n",
      "[CV 5/5] END C=0.1, gamma=0.001, kernel=rbf;, score=(train=0.874, test=0.875) total time=   1.3s\n",
      "[CV 1/5] END C=0.1, gamma=0.0001, kernel=rbf;, score=(train=0.875, test=0.874) total time=   1.0s\n",
      "[CV 2/5] END C=0.1, gamma=0.0001, kernel=rbf;, score=(train=0.875, test=0.874) total time=   1.1s\n",
      "[CV 3/5] END C=0.1, gamma=0.0001, kernel=rbf;, score=(train=0.875, test=0.874) total time=   1.2s\n",
      "[CV 4/5] END C=0.1, gamma=0.0001, kernel=rbf;, score=(train=0.875, test=0.874) total time=   1.4s\n",
      "[CV 5/5] END C=0.1, gamma=0.0001, kernel=rbf;, score=(train=0.874, test=0.875) total time=   1.1s\n",
      "[CV 1/5] END C=1, gamma=1, kernel=rbf;, score=(train=1.000, test=0.874) total time=   5.5s\n",
      "[CV 2/5] END C=1, gamma=1, kernel=rbf;, score=(train=1.000, test=0.874) total time=   5.5s\n",
      "[CV 3/5] END C=1, gamma=1, kernel=rbf;, score=(train=1.000, test=0.874) total time=   5.7s\n",
      "[CV 4/5] END C=1, gamma=1, kernel=rbf;, score=(train=1.000, test=0.874) total time=   5.6s\n",
      "[CV 5/5] END C=1, gamma=1, kernel=rbf;, score=(train=1.000, test=0.875) total time=   5.5s\n",
      "[CV 1/5] END C=1, gamma=0.1, kernel=rbf;, score=(train=1.000, test=0.874) total time=   5.5s\n",
      "[CV 2/5] END C=1, gamma=0.1, kernel=rbf;, score=(train=1.000, test=0.874) total time=   5.7s\n",
      "[CV 3/5] END C=1, gamma=0.1, kernel=rbf;, score=(train=1.000, test=0.874) total time=   5.3s\n",
      "[CV 4/5] END C=1, gamma=0.1, kernel=rbf;, score=(train=1.000, test=0.874) total time=   5.7s\n",
      "[CV 5/5] END C=1, gamma=0.1, kernel=rbf;, score=(train=1.000, test=0.875) total time=   5.3s\n",
      "[CV 1/5] END C=1, gamma=0.01, kernel=rbf;, score=(train=0.994, test=0.953) total time=   1.1s\n",
      "[CV 2/5] END C=1, gamma=0.01, kernel=rbf;, score=(train=0.992, test=0.956) total time=   1.4s\n",
      "[CV 3/5] END C=1, gamma=0.01, kernel=rbf;, score=(train=0.993, test=0.953) total time=   1.3s\n",
      "[CV 4/5] END C=1, gamma=0.01, kernel=rbf;, score=(train=0.993, test=0.956) total time=   1.4s\n",
      "[CV 5/5] END C=1, gamma=0.01, kernel=rbf;, score=(train=0.994, test=0.956) total time=   1.4s\n",
      "[CV 1/5] END C=1, gamma=0.001, kernel=rbf;, score=(train=0.936, test=0.931) total time=   1.0s\n",
      "[CV 2/5] END C=1, gamma=0.001, kernel=rbf;, score=(train=0.938, test=0.931) total time=   1.3s\n",
      "[CV 3/5] END C=1, gamma=0.001, kernel=rbf;, score=(train=0.938, test=0.934) total time=   1.3s\n",
      "[CV 4/5] END C=1, gamma=0.001, kernel=rbf;, score=(train=0.939, test=0.928) total time=   1.1s\n",
      "[CV 5/5] END C=1, gamma=0.001, kernel=rbf;, score=(train=0.939, test=0.939) total time=   1.4s\n",
      "[CV 1/5] END C=1, gamma=0.0001, kernel=rbf;, score=(train=0.875, test=0.874) total time=   1.3s\n",
      "[CV 2/5] END C=1, gamma=0.0001, kernel=rbf;, score=(train=0.875, test=0.874) total time=   1.0s\n",
      "[CV 3/5] END C=1, gamma=0.0001, kernel=rbf;, score=(train=0.875, test=0.874) total time=   1.4s\n",
      "[CV 4/5] END C=1, gamma=0.0001, kernel=rbf;, score=(train=0.875, test=0.874) total time=   1.3s\n",
      "[CV 5/5] END C=1, gamma=0.0001, kernel=rbf;, score=(train=0.874, test=0.875) total time=   1.2s\n",
      "[CV 1/5] END C=10, gamma=1, kernel=rbf;, score=(train=1.000, test=0.874) total time=   5.5s\n",
      "[CV 2/5] END C=10, gamma=1, kernel=rbf;, score=(train=1.000, test=0.874) total time=   5.5s\n",
      "[CV 3/5] END C=10, gamma=1, kernel=rbf;, score=(train=1.000, test=0.874) total time=   5.8s\n",
      "[CV 4/5] END C=10, gamma=1, kernel=rbf;, score=(train=1.000, test=0.874) total time=   5.6s\n",
      "[CV 5/5] END C=10, gamma=1, kernel=rbf;, score=(train=1.000, test=0.875) total time=   5.7s\n",
      "[CV 1/5] END C=10, gamma=0.1, kernel=rbf;, score=(train=1.000, test=0.874) total time=   6.0s\n",
      "[CV 2/5] END C=10, gamma=0.1, kernel=rbf;, score=(train=1.000, test=0.874) total time=   6.0s\n",
      "[CV 3/5] END C=10, gamma=0.1, kernel=rbf;, score=(train=1.000, test=0.874) total time=   5.8s\n",
      "[CV 4/5] END C=10, gamma=0.1, kernel=rbf;, score=(train=1.000, test=0.874) total time=   5.4s\n",
      "[CV 5/5] END C=10, gamma=0.1, kernel=rbf;, score=(train=1.000, test=0.875) total time=   5.9s\n",
      "[CV 1/5] END C=10, gamma=0.01, kernel=rbf;, score=(train=1.000, test=0.963) total time=   1.4s\n",
      "[CV 2/5] END C=10, gamma=0.01, kernel=rbf;, score=(train=1.000, test=0.959) total time=   1.2s\n",
      "[CV 3/5] END C=10, gamma=0.01, kernel=rbf;, score=(train=1.000, test=0.958) total time=   1.2s\n",
      "[CV 4/5] END C=10, gamma=0.01, kernel=rbf;, score=(train=1.000, test=0.959) total time=   1.3s\n",
      "[CV 5/5] END C=10, gamma=0.01, kernel=rbf;, score=(train=1.000, test=0.966) total time=   1.3s\n",
      "[CV 1/5] END C=10, gamma=0.001, kernel=rbf;, score=(train=0.981, test=0.975) total time=   0.8s\n",
      "[CV 2/5] END C=10, gamma=0.001, kernel=rbf;, score=(train=0.983, test=0.971) total time=   0.8s\n",
      "[CV 3/5] END C=10, gamma=0.001, kernel=rbf;, score=(train=0.985, test=0.963) total time=   0.8s\n",
      "[CV 4/5] END C=10, gamma=0.001, kernel=rbf;, score=(train=0.984, test=0.964) total time=   0.6s\n",
      "[CV 5/5] END C=10, gamma=0.001, kernel=rbf;, score=(train=0.984, test=0.969) total time=   0.6s\n",
      "[CV 1/5] END C=10, gamma=0.0001, kernel=rbf;, score=(train=0.941, test=0.936) total time=   1.1s\n",
      "[CV 2/5] END C=10, gamma=0.0001, kernel=rbf;, score=(train=0.940, test=0.937) total time=   1.3s\n",
      "[CV 3/5] END C=10, gamma=0.0001, kernel=rbf;, score=(train=0.941, test=0.941) total time=   1.2s\n",
      "[CV 4/5] END C=10, gamma=0.0001, kernel=rbf;, score=(train=0.942, test=0.934) total time=   0.9s\n",
      "[CV 5/5] END C=10, gamma=0.0001, kernel=rbf;, score=(train=0.941, test=0.941) total time=   1.2s\n",
      "[CV 1/5] END C=100, gamma=1, kernel=rbf;, score=(train=1.000, test=0.874) total time=   6.0s\n",
      "[CV 2/5] END C=100, gamma=1, kernel=rbf;, score=(train=1.000, test=0.874) total time=   5.5s\n",
      "[CV 3/5] END C=100, gamma=1, kernel=rbf;, score=(train=1.000, test=0.874) total time=   5.9s\n",
      "[CV 4/5] END C=100, gamma=1, kernel=rbf;, score=(train=1.000, test=0.874) total time=   5.6s\n",
      "[CV 5/5] END C=100, gamma=1, kernel=rbf;, score=(train=1.000, test=0.875) total time=   5.2s\n",
      "[CV 1/5] END C=100, gamma=0.1, kernel=rbf;, score=(train=1.000, test=0.874) total time=   5.7s\n",
      "[CV 2/5] END C=100, gamma=0.1, kernel=rbf;, score=(train=1.000, test=0.874) total time=   5.3s\n",
      "[CV 3/5] END C=100, gamma=0.1, kernel=rbf;, score=(train=1.000, test=0.874) total time=   5.8s\n",
      "[CV 4/5] END C=100, gamma=0.1, kernel=rbf;, score=(train=1.000, test=0.874) total time=   5.7s\n",
      "[CV 5/5] END C=100, gamma=0.1, kernel=rbf;, score=(train=1.000, test=0.875) total time=   6.4s\n",
      "[CV 1/5] END C=100, gamma=0.01, kernel=rbf;, score=(train=1.000, test=0.963) total time=   1.5s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=100, gamma=0.01, kernel=rbf;, score=(train=1.000, test=0.959) total time=   1.7s\n",
      "[CV 3/5] END C=100, gamma=0.01, kernel=rbf;, score=(train=1.000, test=0.958) total time=   1.2s\n",
      "[CV 4/5] END C=100, gamma=0.01, kernel=rbf;, score=(train=1.000, test=0.959) total time=   1.3s\n",
      "[CV 5/5] END C=100, gamma=0.01, kernel=rbf;, score=(train=1.000, test=0.966) total time=   1.4s\n",
      "[CV 1/5] END C=100, gamma=0.001, kernel=rbf;, score=(train=0.998, test=0.971) total time=   0.6s\n",
      "[CV 2/5] END C=100, gamma=0.001, kernel=rbf;, score=(train=0.998, test=0.975) total time=   0.9s\n",
      "[CV 3/5] END C=100, gamma=0.001, kernel=rbf;, score=(train=0.998, test=0.966) total time=   0.8s\n",
      "[CV 4/5] END C=100, gamma=0.001, kernel=rbf;, score=(train=0.999, test=0.969) total time=   0.8s\n",
      "[CV 5/5] END C=100, gamma=0.001, kernel=rbf;, score=(train=0.998, test=0.969) total time=   0.7s\n",
      "[CV 1/5] END C=100, gamma=0.0001, kernel=rbf;, score=(train=0.977, test=0.974) total time=   0.8s\n",
      "[CV 2/5] END C=100, gamma=0.0001, kernel=rbf;, score=(train=0.977, test=0.974) total time=   0.7s\n",
      "[CV 3/5] END C=100, gamma=0.0001, kernel=rbf;, score=(train=0.979, test=0.964) total time=   0.7s\n",
      "[CV 4/5] END C=100, gamma=0.0001, kernel=rbf;, score=(train=0.977, test=0.964) total time=   0.6s\n",
      "[CV 5/5] END C=100, gamma=0.0001, kernel=rbf;, score=(train=0.977, test=0.967) total time=   0.7s\n",
      "[CV 1/5] END C=1000, gamma=1, kernel=rbf;, score=(train=1.000, test=0.874) total time=   6.3s\n",
      "[CV 2/5] END C=1000, gamma=1, kernel=rbf;, score=(train=1.000, test=0.874) total time=   6.3s\n",
      "[CV 3/5] END C=1000, gamma=1, kernel=rbf;, score=(train=1.000, test=0.874) total time=   5.8s\n",
      "[CV 4/5] END C=1000, gamma=1, kernel=rbf;, score=(train=1.000, test=0.874) total time=   6.2s\n",
      "[CV 5/5] END C=1000, gamma=1, kernel=rbf;, score=(train=1.000, test=0.875) total time=   6.0s\n",
      "[CV 1/5] END C=1000, gamma=0.1, kernel=rbf;, score=(train=1.000, test=0.874) total time=   6.1s\n",
      "[CV 2/5] END C=1000, gamma=0.1, kernel=rbf;, score=(train=1.000, test=0.874) total time=   6.3s\n",
      "[CV 3/5] END C=1000, gamma=0.1, kernel=rbf;, score=(train=1.000, test=0.874) total time=   6.9s\n",
      "[CV 4/5] END C=1000, gamma=0.1, kernel=rbf;, score=(train=1.000, test=0.874) total time=   6.3s\n",
      "[CV 5/5] END C=1000, gamma=0.1, kernel=rbf;, score=(train=1.000, test=0.875) total time=   7.0s\n",
      "[CV 1/5] END C=1000, gamma=0.01, kernel=rbf;, score=(train=1.000, test=0.963) total time=   1.6s\n",
      "[CV 2/5] END C=1000, gamma=0.01, kernel=rbf;, score=(train=1.000, test=0.959) total time=   1.5s\n",
      "[CV 3/5] END C=1000, gamma=0.01, kernel=rbf;, score=(train=1.000, test=0.958) total time=   1.5s\n",
      "[CV 4/5] END C=1000, gamma=0.01, kernel=rbf;, score=(train=1.000, test=0.959) total time=   1.8s\n",
      "[CV 5/5] END C=1000, gamma=0.01, kernel=rbf;, score=(train=1.000, test=0.966) total time=   1.6s\n",
      "[CV 1/5] END C=1000, gamma=0.001, kernel=rbf;, score=(train=1.000, test=0.969) total time=   0.8s\n",
      "[CV 2/5] END C=1000, gamma=0.001, kernel=rbf;, score=(train=1.000, test=0.975) total time=   1.0s\n",
      "[CV 3/5] END C=1000, gamma=0.001, kernel=rbf;, score=(train=1.000, test=0.964) total time=   0.8s\n",
      "[CV 4/5] END C=1000, gamma=0.001, kernel=rbf;, score=(train=1.000, test=0.966) total time=   0.9s\n",
      "[CV 5/5] END C=1000, gamma=0.001, kernel=rbf;, score=(train=1.000, test=0.971) total time=   0.8s\n",
      "[CV 1/5] END C=1000, gamma=0.0001, kernel=rbf;, score=(train=0.983, test=0.978) total time=   0.5s\n",
      "[CV 2/5] END C=1000, gamma=0.0001, kernel=rbf;, score=(train=0.983, test=0.976) total time=   0.7s\n",
      "[CV 3/5] END C=1000, gamma=0.0001, kernel=rbf;, score=(train=0.985, test=0.969) total time=   0.6s\n",
      "[CV 4/5] END C=1000, gamma=0.0001, kernel=rbf;, score=(train=0.983, test=0.973) total time=   0.8s\n",
      "[CV 5/5] END C=1000, gamma=0.0001, kernel=rbf;, score=(train=0.984, test=0.969) total time=   0.9s\n",
      "SVC(C=1000, gamma=0.0001)\n"
     ]
    }
   ],
   "source": [
    "grid_svm.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 1000, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
      "SVC(C=1000, gamma=0.0001)\n"
     ]
    }
   ],
   "source": [
    "print(grid_svm.best_params_)  \n",
    "# print model after tuning\n",
    "print(grid_svm.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_predictions = grid_svm.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the confusion matrix \n",
      " [[6938   57]\n",
      " [  74  930]] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Confusion matrix: \\n\",\n",
    "      confusion_matrix(y_train, grid_predictions), \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99      6995\n",
      "           1       0.94      0.93      0.93      1004\n",
      "\n",
      "    accuracy                           0.98      7999\n",
      "   macro avg       0.97      0.96      0.96      7999\n",
      "weighted avg       0.98      0.98      0.98      7999\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_train, grid_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_predictions = grid_svm.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the confusion matrix \n",
      " [[1742   28]\n",
      " [  21  209]] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"This is the confusion matrix \\n\",\n",
    "      confusion_matrix(y_test, grid_predictions), \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.98      0.99      1770\n",
      "           1       0.88      0.91      0.90       230\n",
      "\n",
      "    accuracy                           0.98      2000\n",
      "   macro avg       0.93      0.95      0.94      2000\n",
      "weighted avg       0.98      0.98      0.98      2000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, grid_predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implement random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\"n_estimators\": [300, 500, 1000],\n",
    "              \"max_depth\": [1, 3, 5, 10],\n",
    "              \"min_samples_split\": [2, 4, 6, 8]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Random Forest Model Performance:\n",
      "Confusion Matrix:\n",
      "[[1770    0]\n",
      " [ 229    1]]\n",
      "Precision: 1.0\n",
      "Recall: 0.004347826086956522\n",
      "F1 Score: 0.008658008658008658\n",
      "Accuracy: 0.8855\n"
     ]
    }
   ],
   "source": [
    "rf_model = RandomForestClassifier(random_state=42, class_weight=\"balanced\")\n",
    "\n",
    "rf_model.fit(X_train, y_train)\n",
    "y_pred_rf = rf_model.predict(X_test)\n",
    "print(\"\\nRandom Forest Model Performance:\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred_rf))\n",
    "print(\"Precision:\", precision_score(y_test, y_pred_rf))\n",
    "print(\"Recall:\", recall_score(y_test, y_pred_rf))\n",
    "print(\"F1 Score:\", f1_score(y_test, y_pred_rf))\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred_rf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_rf = GridSearchCV(estimator=rf_model, \n",
    "                       param_grid=param_grid, \n",
    "                       refit=True, verbose=3, \n",
    "                       cv=5,\n",
    "                       return_train_score=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 48 candidates, totalling 240 fits\n",
      "[CV 1/5] END max_depth=1, min_samples_split=2, n_estimators=300;, score=(train=0.833, test=0.824) total time=   1.1s\n",
      "[CV 2/5] END max_depth=1, min_samples_split=2, n_estimators=300;, score=(train=0.836, test=0.818) total time=   1.1s\n",
      "[CV 3/5] END max_depth=1, min_samples_split=2, n_estimators=300;, score=(train=0.823, test=0.814) total time=   1.0s\n",
      "[CV 4/5] END max_depth=1, min_samples_split=2, n_estimators=300;, score=(train=0.825, test=0.821) total time=   0.9s\n",
      "[CV 5/5] END max_depth=1, min_samples_split=2, n_estimators=300;, score=(train=0.832, test=0.833) total time=   0.8s\n",
      "[CV 1/5] END max_depth=1, min_samples_split=2, n_estimators=500;, score=(train=0.833, test=0.817) total time=   1.4s\n",
      "[CV 2/5] END max_depth=1, min_samples_split=2, n_estimators=500;, score=(train=0.837, test=0.821) total time=   1.3s\n",
      "[CV 3/5] END max_depth=1, min_samples_split=2, n_estimators=500;, score=(train=0.830, test=0.821) total time=   1.4s\n",
      "[CV 4/5] END max_depth=1, min_samples_split=2, n_estimators=500;, score=(train=0.827, test=0.820) total time=   1.4s\n",
      "[CV 5/5] END max_depth=1, min_samples_split=2, n_estimators=500;, score=(train=0.836, test=0.834) total time=   1.4s\n",
      "[CV 1/5] END max_depth=1, min_samples_split=2, n_estimators=1000;, score=(train=0.834, test=0.827) total time=   3.0s\n",
      "[CV 2/5] END max_depth=1, min_samples_split=2, n_estimators=1000;, score=(train=0.836, test=0.819) total time=   2.6s\n",
      "[CV 3/5] END max_depth=1, min_samples_split=2, n_estimators=1000;, score=(train=0.831, test=0.828) total time=   2.7s\n",
      "[CV 4/5] END max_depth=1, min_samples_split=2, n_estimators=1000;, score=(train=0.830, test=0.823) total time=   2.8s\n",
      "[CV 5/5] END max_depth=1, min_samples_split=2, n_estimators=1000;, score=(train=0.836, test=0.831) total time=   2.8s\n",
      "[CV 1/5] END max_depth=1, min_samples_split=4, n_estimators=300;, score=(train=0.833, test=0.824) total time=   0.8s\n",
      "[CV 2/5] END max_depth=1, min_samples_split=4, n_estimators=300;, score=(train=0.836, test=0.818) total time=   0.8s\n",
      "[CV 3/5] END max_depth=1, min_samples_split=4, n_estimators=300;, score=(train=0.823, test=0.814) total time=   0.8s\n",
      "[CV 4/5] END max_depth=1, min_samples_split=4, n_estimators=300;, score=(train=0.825, test=0.821) total time=   0.8s\n",
      "[CV 5/5] END max_depth=1, min_samples_split=4, n_estimators=300;, score=(train=0.832, test=0.833) total time=   0.9s\n",
      "[CV 1/5] END max_depth=1, min_samples_split=4, n_estimators=500;, score=(train=0.833, test=0.817) total time=   1.3s\n",
      "[CV 2/5] END max_depth=1, min_samples_split=4, n_estimators=500;, score=(train=0.837, test=0.821) total time=   1.4s\n",
      "[CV 3/5] END max_depth=1, min_samples_split=4, n_estimators=500;, score=(train=0.830, test=0.821) total time=   1.5s\n",
      "[CV 4/5] END max_depth=1, min_samples_split=4, n_estimators=500;, score=(train=0.827, test=0.820) total time=   1.1s\n",
      "[CV 5/5] END max_depth=1, min_samples_split=4, n_estimators=500;, score=(train=0.836, test=0.834) total time=   1.5s\n",
      "[CV 1/5] END max_depth=1, min_samples_split=4, n_estimators=1000;, score=(train=0.834, test=0.827) total time=   3.0s\n",
      "[CV 2/5] END max_depth=1, min_samples_split=4, n_estimators=1000;, score=(train=0.836, test=0.819) total time=   2.9s\n",
      "[CV 3/5] END max_depth=1, min_samples_split=4, n_estimators=1000;, score=(train=0.831, test=0.828) total time=   2.9s\n",
      "[CV 4/5] END max_depth=1, min_samples_split=4, n_estimators=1000;, score=(train=0.830, test=0.823) total time=   3.0s\n",
      "[CV 5/5] END max_depth=1, min_samples_split=4, n_estimators=1000;, score=(train=0.836, test=0.831) total time=   3.0s\n",
      "[CV 1/5] END max_depth=1, min_samples_split=6, n_estimators=300;, score=(train=0.833, test=0.824) total time=   1.0s\n",
      "[CV 2/5] END max_depth=1, min_samples_split=6, n_estimators=300;, score=(train=0.836, test=0.818) total time=   0.9s\n",
      "[CV 3/5] END max_depth=1, min_samples_split=6, n_estimators=300;, score=(train=0.823, test=0.814) total time=   0.8s\n",
      "[CV 4/5] END max_depth=1, min_samples_split=6, n_estimators=300;, score=(train=0.825, test=0.821) total time=   0.8s\n",
      "[CV 5/5] END max_depth=1, min_samples_split=6, n_estimators=300;, score=(train=0.832, test=0.833) total time=   0.8s\n",
      "[CV 1/5] END max_depth=1, min_samples_split=6, n_estimators=500;, score=(train=0.833, test=0.817) total time=   1.3s\n",
      "[CV 2/5] END max_depth=1, min_samples_split=6, n_estimators=500;, score=(train=0.837, test=0.821) total time=   1.3s\n",
      "[CV 3/5] END max_depth=1, min_samples_split=6, n_estimators=500;, score=(train=0.830, test=0.821) total time=   1.4s\n",
      "[CV 4/5] END max_depth=1, min_samples_split=6, n_estimators=500;, score=(train=0.827, test=0.820) total time=   1.2s\n",
      "[CV 5/5] END max_depth=1, min_samples_split=6, n_estimators=500;, score=(train=0.836, test=0.834) total time=   1.4s\n",
      "[CV 1/5] END max_depth=1, min_samples_split=6, n_estimators=1000;, score=(train=0.834, test=0.827) total time=   2.7s\n",
      "[CV 2/5] END max_depth=1, min_samples_split=6, n_estimators=1000;, score=(train=0.836, test=0.819) total time=   3.1s\n",
      "[CV 3/5] END max_depth=1, min_samples_split=6, n_estimators=1000;, score=(train=0.831, test=0.828) total time=   3.0s\n",
      "[CV 4/5] END max_depth=1, min_samples_split=6, n_estimators=1000;, score=(train=0.830, test=0.823) total time=   2.9s\n",
      "[CV 5/5] END max_depth=1, min_samples_split=6, n_estimators=1000;, score=(train=0.836, test=0.831) total time=   2.7s\n",
      "[CV 1/5] END max_depth=1, min_samples_split=8, n_estimators=300;, score=(train=0.833, test=0.824) total time=   0.8s\n",
      "[CV 2/5] END max_depth=1, min_samples_split=8, n_estimators=300;, score=(train=0.836, test=0.818) total time=   0.7s\n",
      "[CV 3/5] END max_depth=1, min_samples_split=8, n_estimators=300;, score=(train=0.823, test=0.814) total time=   0.7s\n",
      "[CV 4/5] END max_depth=1, min_samples_split=8, n_estimators=300;, score=(train=0.825, test=0.821) total time=   0.8s\n",
      "[CV 5/5] END max_depth=1, min_samples_split=8, n_estimators=300;, score=(train=0.832, test=0.833) total time=   0.8s\n",
      "[CV 1/5] END max_depth=1, min_samples_split=8, n_estimators=500;, score=(train=0.833, test=0.817) total time=   1.3s\n",
      "[CV 2/5] END max_depth=1, min_samples_split=8, n_estimators=500;, score=(train=0.837, test=0.821) total time=   1.4s\n",
      "[CV 3/5] END max_depth=1, min_samples_split=8, n_estimators=500;, score=(train=0.830, test=0.821) total time=   1.4s\n",
      "[CV 4/5] END max_depth=1, min_samples_split=8, n_estimators=500;, score=(train=0.827, test=0.820) total time=   1.3s\n",
      "[CV 5/5] END max_depth=1, min_samples_split=8, n_estimators=500;, score=(train=0.836, test=0.834) total time=   0.7s\n",
      "[CV 1/5] END max_depth=1, min_samples_split=8, n_estimators=1000;, score=(train=0.834, test=0.827) total time=   2.9s\n",
      "[CV 2/5] END max_depth=1, min_samples_split=8, n_estimators=1000;, score=(train=0.836, test=0.819) total time=   2.9s\n",
      "[CV 3/5] END max_depth=1, min_samples_split=8, n_estimators=1000;, score=(train=0.831, test=0.828) total time=   3.0s\n",
      "[CV 4/5] END max_depth=1, min_samples_split=8, n_estimators=1000;, score=(train=0.830, test=0.823) total time=   2.9s\n",
      "[CV 5/5] END max_depth=1, min_samples_split=8, n_estimators=1000;, score=(train=0.836, test=0.831) total time=   2.9s\n",
      "[CV 1/5] END max_depth=3, min_samples_split=2, n_estimators=300;, score=(train=0.856, test=0.839) total time=   1.1s\n",
      "[CV 2/5] END max_depth=3, min_samples_split=2, n_estimators=300;, score=(train=0.857, test=0.836) total time=   1.1s\n",
      "[CV 3/5] END max_depth=3, min_samples_split=2, n_estimators=300;, score=(train=0.846, test=0.828) total time=   1.1s\n",
      "[CV 4/5] END max_depth=3, min_samples_split=2, n_estimators=300;, score=(train=0.854, test=0.841) total time=   1.2s\n",
      "[CV 5/5] END max_depth=3, min_samples_split=2, n_estimators=300;, score=(train=0.858, test=0.842) total time=   1.0s\n",
      "[CV 1/5] END max_depth=3, min_samples_split=2, n_estimators=500;, score=(train=0.854, test=0.840) total time=   1.9s\n",
      "[CV 2/5] END max_depth=3, min_samples_split=2, n_estimators=500;, score=(train=0.857, test=0.840) total time=   2.0s\n",
      "[CV 3/5] END max_depth=3, min_samples_split=2, n_estimators=500;, score=(train=0.849, test=0.833) total time=   2.1s\n",
      "[CV 4/5] END max_depth=3, min_samples_split=2, n_estimators=500;, score=(train=0.854, test=0.836) total time=   2.0s\n",
      "[CV 5/5] END max_depth=3, min_samples_split=2, n_estimators=500;, score=(train=0.859, test=0.849) total time=   1.9s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END max_depth=3, min_samples_split=2, n_estimators=1000;, score=(train=0.856, test=0.842) total time=   3.8s\n",
      "[CV 2/5] END max_depth=3, min_samples_split=2, n_estimators=1000;, score=(train=0.855, test=0.836) total time=   3.9s\n",
      "[CV 3/5] END max_depth=3, min_samples_split=2, n_estimators=1000;, score=(train=0.851, test=0.832) total time=   4.1s\n",
      "[CV 4/5] END max_depth=3, min_samples_split=2, n_estimators=1000;, score=(train=0.853, test=0.838) total time=   3.8s\n",
      "[CV 5/5] END max_depth=3, min_samples_split=2, n_estimators=1000;, score=(train=0.859, test=0.847) total time=   3.9s\n",
      "[CV 1/5] END max_depth=3, min_samples_split=4, n_estimators=300;, score=(train=0.856, test=0.839) total time=   1.0s\n",
      "[CV 2/5] END max_depth=3, min_samples_split=4, n_estimators=300;, score=(train=0.857, test=0.836) total time=   1.2s\n",
      "[CV 3/5] END max_depth=3, min_samples_split=4, n_estimators=300;, score=(train=0.846, test=0.828) total time=   1.3s\n",
      "[CV 4/5] END max_depth=3, min_samples_split=4, n_estimators=300;, score=(train=0.854, test=0.841) total time=   1.2s\n",
      "[CV 5/5] END max_depth=3, min_samples_split=4, n_estimators=300;, score=(train=0.858, test=0.842) total time=   1.0s\n",
      "[CV 1/5] END max_depth=3, min_samples_split=4, n_estimators=500;, score=(train=0.854, test=0.840) total time=   1.9s\n",
      "[CV 2/5] END max_depth=3, min_samples_split=4, n_estimators=500;, score=(train=0.856, test=0.839) total time=   2.0s\n",
      "[CV 3/5] END max_depth=3, min_samples_split=4, n_estimators=500;, score=(train=0.849, test=0.833) total time=   2.0s\n",
      "[CV 4/5] END max_depth=3, min_samples_split=4, n_estimators=500;, score=(train=0.854, test=0.836) total time=   1.8s\n",
      "[CV 5/5] END max_depth=3, min_samples_split=4, n_estimators=500;, score=(train=0.859, test=0.849) total time=   1.9s\n",
      "[CV 1/5] END max_depth=3, min_samples_split=4, n_estimators=1000;, score=(train=0.856, test=0.842) total time=   4.0s\n",
      "[CV 2/5] END max_depth=3, min_samples_split=4, n_estimators=1000;, score=(train=0.855, test=0.836) total time=   4.1s\n",
      "[CV 3/5] END max_depth=3, min_samples_split=4, n_estimators=1000;, score=(train=0.851, test=0.832) total time=   4.3s\n",
      "[CV 4/5] END max_depth=3, min_samples_split=4, n_estimators=1000;, score=(train=0.853, test=0.838) total time=   3.9s\n",
      "[CV 5/5] END max_depth=3, min_samples_split=4, n_estimators=1000;, score=(train=0.859, test=0.847) total time=   4.0s\n",
      "[CV 1/5] END max_depth=3, min_samples_split=6, n_estimators=300;, score=(train=0.856, test=0.839) total time=   1.3s\n",
      "[CV 2/5] END max_depth=3, min_samples_split=6, n_estimators=300;, score=(train=0.857, test=0.836) total time=   1.3s\n",
      "[CV 3/5] END max_depth=3, min_samples_split=6, n_estimators=300;, score=(train=0.846, test=0.828) total time=   1.2s\n",
      "[CV 4/5] END max_depth=3, min_samples_split=6, n_estimators=300;, score=(train=0.854, test=0.841) total time=   1.2s\n",
      "[CV 5/5] END max_depth=3, min_samples_split=6, n_estimators=300;, score=(train=0.858, test=0.842) total time=   1.1s\n",
      "[CV 1/5] END max_depth=3, min_samples_split=6, n_estimators=500;, score=(train=0.854, test=0.840) total time=   2.1s\n",
      "[CV 2/5] END max_depth=3, min_samples_split=6, n_estimators=500;, score=(train=0.856, test=0.839) total time=   2.0s\n",
      "[CV 3/5] END max_depth=3, min_samples_split=6, n_estimators=500;, score=(train=0.849, test=0.833) total time=   1.9s\n",
      "[CV 4/5] END max_depth=3, min_samples_split=6, n_estimators=500;, score=(train=0.854, test=0.836) total time=   2.1s\n",
      "[CV 5/5] END max_depth=3, min_samples_split=6, n_estimators=500;, score=(train=0.859, test=0.849) total time=   1.7s\n",
      "[CV 1/5] END max_depth=3, min_samples_split=6, n_estimators=1000;, score=(train=0.856, test=0.842) total time=   4.1s\n",
      "[CV 2/5] END max_depth=3, min_samples_split=6, n_estimators=1000;, score=(train=0.855, test=0.836) total time=   4.1s\n",
      "[CV 3/5] END max_depth=3, min_samples_split=6, n_estimators=1000;, score=(train=0.851, test=0.832) total time=   4.1s\n",
      "[CV 4/5] END max_depth=3, min_samples_split=6, n_estimators=1000;, score=(train=0.853, test=0.838) total time=   4.6s\n",
      "[CV 5/5] END max_depth=3, min_samples_split=6, n_estimators=1000;, score=(train=0.859, test=0.847) total time=   4.1s\n",
      "[CV 1/5] END max_depth=3, min_samples_split=8, n_estimators=300;, score=(train=0.856, test=0.839) total time=   1.1s\n",
      "[CV 2/5] END max_depth=3, min_samples_split=8, n_estimators=300;, score=(train=0.857, test=0.836) total time=   1.1s\n",
      "[CV 3/5] END max_depth=3, min_samples_split=8, n_estimators=300;, score=(train=0.846, test=0.828) total time=   1.2s\n",
      "[CV 4/5] END max_depth=3, min_samples_split=8, n_estimators=300;, score=(train=0.854, test=0.841) total time=   1.0s\n",
      "[CV 5/5] END max_depth=3, min_samples_split=8, n_estimators=300;, score=(train=0.858, test=0.842) total time=   1.3s\n",
      "[CV 1/5] END max_depth=3, min_samples_split=8, n_estimators=500;, score=(train=0.854, test=0.840) total time=   2.0s\n",
      "[CV 2/5] END max_depth=3, min_samples_split=8, n_estimators=500;, score=(train=0.856, test=0.839) total time=   1.9s\n",
      "[CV 3/5] END max_depth=3, min_samples_split=8, n_estimators=500;, score=(train=0.849, test=0.833) total time=   1.8s\n",
      "[CV 4/5] END max_depth=3, min_samples_split=8, n_estimators=500;, score=(train=0.854, test=0.836) total time=   1.8s\n",
      "[CV 5/5] END max_depth=3, min_samples_split=8, n_estimators=500;, score=(train=0.859, test=0.849) total time=   1.9s\n",
      "[CV 1/5] END max_depth=3, min_samples_split=8, n_estimators=1000;, score=(train=0.856, test=0.842) total time=   4.1s\n",
      "[CV 2/5] END max_depth=3, min_samples_split=8, n_estimators=1000;, score=(train=0.855, test=0.836) total time=   4.1s\n",
      "[CV 3/5] END max_depth=3, min_samples_split=8, n_estimators=1000;, score=(train=0.851, test=0.832) total time=   3.9s\n",
      "[CV 4/5] END max_depth=3, min_samples_split=8, n_estimators=1000;, score=(train=0.853, test=0.838) total time=   3.9s\n",
      "[CV 5/5] END max_depth=3, min_samples_split=8, n_estimators=1000;, score=(train=0.859, test=0.847) total time=   4.0s\n",
      "[CV 1/5] END max_depth=5, min_samples_split=2, n_estimators=300;, score=(train=0.897, test=0.863) total time=   1.4s\n",
      "[CV 2/5] END max_depth=5, min_samples_split=2, n_estimators=300;, score=(train=0.899, test=0.863) total time=   1.5s\n",
      "[CV 3/5] END max_depth=5, min_samples_split=2, n_estimators=300;, score=(train=0.893, test=0.861) total time=   1.3s\n",
      "[CV 4/5] END max_depth=5, min_samples_split=2, n_estimators=300;, score=(train=0.899, test=0.869) total time=   1.7s\n",
      "[CV 5/5] END max_depth=5, min_samples_split=2, n_estimators=300;, score=(train=0.902, test=0.873) total time=   1.6s\n",
      "[CV 1/5] END max_depth=5, min_samples_split=2, n_estimators=500;, score=(train=0.896, test=0.863) total time=   2.7s\n",
      "[CV 2/5] END max_depth=5, min_samples_split=2, n_estimators=500;, score=(train=0.901, test=0.862) total time=   2.5s\n",
      "[CV 3/5] END max_depth=5, min_samples_split=2, n_estimators=500;, score=(train=0.898, test=0.868) total time=   2.5s\n",
      "[CV 4/5] END max_depth=5, min_samples_split=2, n_estimators=500;, score=(train=0.898, test=0.865) total time=   2.2s\n",
      "[CV 5/5] END max_depth=5, min_samples_split=2, n_estimators=500;, score=(train=0.906, test=0.876) total time=   2.4s\n",
      "[CV 1/5] END max_depth=5, min_samples_split=2, n_estimators=1000;, score=(train=0.899, test=0.866) total time=   4.9s\n",
      "[CV 2/5] END max_depth=5, min_samples_split=2, n_estimators=1000;, score=(train=0.900, test=0.864) total time=   4.9s\n",
      "[CV 3/5] END max_depth=5, min_samples_split=2, n_estimators=1000;, score=(train=0.898, test=0.869) total time=   5.2s\n",
      "[CV 4/5] END max_depth=5, min_samples_split=2, n_estimators=1000;, score=(train=0.901, test=0.865) total time=   5.5s\n",
      "[CV 5/5] END max_depth=5, min_samples_split=2, n_estimators=1000;, score=(train=0.907, test=0.882) total time=   5.0s\n",
      "[CV 1/5] END max_depth=5, min_samples_split=4, n_estimators=300;, score=(train=0.897, test=0.860) total time=   1.5s\n",
      "[CV 2/5] END max_depth=5, min_samples_split=4, n_estimators=300;, score=(train=0.900, test=0.864) total time=   1.6s\n",
      "[CV 3/5] END max_depth=5, min_samples_split=4, n_estimators=300;, score=(train=0.893, test=0.862) total time=   1.4s\n",
      "[CV 4/5] END max_depth=5, min_samples_split=4, n_estimators=300;, score=(train=0.899, test=0.869) total time=   1.3s\n",
      "[CV 5/5] END max_depth=5, min_samples_split=4, n_estimators=300;, score=(train=0.902, test=0.874) total time=   1.3s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END max_depth=5, min_samples_split=4, n_estimators=500;, score=(train=0.896, test=0.863) total time=   2.4s\n",
      "[CV 2/5] END max_depth=5, min_samples_split=4, n_estimators=500;, score=(train=0.902, test=0.861) total time=   2.7s\n",
      "[CV 3/5] END max_depth=5, min_samples_split=4, n_estimators=500;, score=(train=0.899, test=0.867) total time=   2.3s\n",
      "[CV 4/5] END max_depth=5, min_samples_split=4, n_estimators=500;, score=(train=0.899, test=0.865) total time=   2.6s\n",
      "[CV 5/5] END max_depth=5, min_samples_split=4, n_estimators=500;, score=(train=0.908, test=0.877) total time=   2.5s\n",
      "[CV 1/5] END max_depth=5, min_samples_split=4, n_estimators=1000;, score=(train=0.900, test=0.865) total time=   5.3s\n",
      "[CV 2/5] END max_depth=5, min_samples_split=4, n_estimators=1000;, score=(train=0.899, test=0.866) total time=   5.0s\n",
      "[CV 3/5] END max_depth=5, min_samples_split=4, n_estimators=1000;, score=(train=0.898, test=0.868) total time=   5.2s\n",
      "[CV 4/5] END max_depth=5, min_samples_split=4, n_estimators=1000;, score=(train=0.901, test=0.866) total time=   5.4s\n",
      "[CV 5/5] END max_depth=5, min_samples_split=4, n_estimators=1000;, score=(train=0.907, test=0.879) total time=   5.4s\n",
      "[CV 1/5] END max_depth=5, min_samples_split=6, n_estimators=300;, score=(train=0.897, test=0.859) total time=   1.6s\n",
      "[CV 2/5] END max_depth=5, min_samples_split=6, n_estimators=300;, score=(train=0.898, test=0.861) total time=   1.5s\n",
      "[CV 3/5] END max_depth=5, min_samples_split=6, n_estimators=300;, score=(train=0.893, test=0.863) total time=   1.7s\n",
      "[CV 4/5] END max_depth=5, min_samples_split=6, n_estimators=300;, score=(train=0.898, test=0.870) total time=   1.5s\n",
      "[CV 5/5] END max_depth=5, min_samples_split=6, n_estimators=300;, score=(train=0.900, test=0.874) total time=   1.5s\n",
      "[CV 1/5] END max_depth=5, min_samples_split=6, n_estimators=500;, score=(train=0.895, test=0.861) total time=   2.9s\n",
      "[CV 2/5] END max_depth=5, min_samples_split=6, n_estimators=500;, score=(train=0.901, test=0.862) total time=   2.8s\n",
      "[CV 3/5] END max_depth=5, min_samples_split=6, n_estimators=500;, score=(train=0.900, test=0.868) total time=   2.5s\n",
      "[CV 4/5] END max_depth=5, min_samples_split=6, n_estimators=500;, score=(train=0.898, test=0.866) total time=   2.7s\n",
      "[CV 5/5] END max_depth=5, min_samples_split=6, n_estimators=500;, score=(train=0.907, test=0.878) total time=   2.6s\n",
      "[CV 1/5] END max_depth=5, min_samples_split=6, n_estimators=1000;, score=(train=0.898, test=0.865) total time=   4.9s\n",
      "[CV 2/5] END max_depth=5, min_samples_split=6, n_estimators=1000;, score=(train=0.899, test=0.866) total time=   5.0s\n",
      "[CV 3/5] END max_depth=5, min_samples_split=6, n_estimators=1000;, score=(train=0.897, test=0.867) total time=   6.0s\n",
      "[CV 4/5] END max_depth=5, min_samples_split=6, n_estimators=1000;, score=(train=0.902, test=0.865) total time=   5.2s\n",
      "[CV 5/5] END max_depth=5, min_samples_split=6, n_estimators=1000;, score=(train=0.907, test=0.877) total time=   5.7s\n",
      "[CV 1/5] END max_depth=5, min_samples_split=8, n_estimators=300;, score=(train=0.897, test=0.861) total time=   1.6s\n",
      "[CV 2/5] END max_depth=5, min_samples_split=8, n_estimators=300;, score=(train=0.898, test=0.861) total time=   1.9s\n",
      "[CV 3/5] END max_depth=5, min_samples_split=8, n_estimators=300;, score=(train=0.893, test=0.862) total time=   1.4s\n",
      "[CV 4/5] END max_depth=5, min_samples_split=8, n_estimators=300;, score=(train=0.898, test=0.869) total time=   1.5s\n",
      "[CV 5/5] END max_depth=5, min_samples_split=8, n_estimators=300;, score=(train=0.900, test=0.875) total time=   1.5s\n",
      "[CV 1/5] END max_depth=5, min_samples_split=8, n_estimators=500;, score=(train=0.895, test=0.861) total time=   2.6s\n",
      "[CV 2/5] END max_depth=5, min_samples_split=8, n_estimators=500;, score=(train=0.900, test=0.861) total time=   2.7s\n",
      "[CV 3/5] END max_depth=5, min_samples_split=8, n_estimators=500;, score=(train=0.900, test=0.869) total time=   2.9s\n",
      "[CV 4/5] END max_depth=5, min_samples_split=8, n_estimators=500;, score=(train=0.898, test=0.869) total time=   2.8s\n",
      "[CV 5/5] END max_depth=5, min_samples_split=8, n_estimators=500;, score=(train=0.907, test=0.878) total time=   2.4s\n",
      "[CV 1/5] END max_depth=5, min_samples_split=8, n_estimators=1000;, score=(train=0.898, test=0.864) total time=   5.5s\n",
      "[CV 2/5] END max_depth=5, min_samples_split=8, n_estimators=1000;, score=(train=0.899, test=0.866) total time=   5.2s\n",
      "[CV 3/5] END max_depth=5, min_samples_split=8, n_estimators=1000;, score=(train=0.897, test=0.868) total time=   5.4s\n",
      "[CV 4/5] END max_depth=5, min_samples_split=8, n_estimators=1000;, score=(train=0.902, test=0.866) total time=   5.7s\n",
      "[CV 5/5] END max_depth=5, min_samples_split=8, n_estimators=1000;, score=(train=0.907, test=0.879) total time=   4.8s\n",
      "[CV 1/5] END max_depth=10, min_samples_split=2, n_estimators=300;, score=(train=0.998, test=0.883) total time=   2.7s\n",
      "[CV 2/5] END max_depth=10, min_samples_split=2, n_estimators=300;, score=(train=0.998, test=0.884) total time=   2.7s\n",
      "[CV 3/5] END max_depth=10, min_samples_split=2, n_estimators=300;, score=(train=0.998, test=0.877) total time=   2.6s\n",
      "[CV 4/5] END max_depth=10, min_samples_split=2, n_estimators=300;, score=(train=0.998, test=0.880) total time=   2.8s\n",
      "[CV 5/5] END max_depth=10, min_samples_split=2, n_estimators=300;, score=(train=0.999, test=0.882) total time=   2.6s\n",
      "[CV 1/5] END max_depth=10, min_samples_split=2, n_estimators=500;, score=(train=0.998, test=0.883) total time=   4.5s\n",
      "[CV 2/5] END max_depth=10, min_samples_split=2, n_estimators=500;, score=(train=0.999, test=0.884) total time=   4.6s\n",
      "[CV 3/5] END max_depth=10, min_samples_split=2, n_estimators=500;, score=(train=0.999, test=0.878) total time=   4.6s\n",
      "[CV 4/5] END max_depth=10, min_samples_split=2, n_estimators=500;, score=(train=0.998, test=0.882) total time=   4.1s\n",
      "[CV 5/5] END max_depth=10, min_samples_split=2, n_estimators=500;, score=(train=0.999, test=0.882) total time=   4.2s\n",
      "[CV 1/5] END max_depth=10, min_samples_split=2, n_estimators=1000;, score=(train=0.998, test=0.884) total time=   8.9s\n",
      "[CV 2/5] END max_depth=10, min_samples_split=2, n_estimators=1000;, score=(train=0.999, test=0.883) total time=   8.8s\n",
      "[CV 3/5] END max_depth=10, min_samples_split=2, n_estimators=1000;, score=(train=0.999, test=0.879) total time=   8.3s\n",
      "[CV 4/5] END max_depth=10, min_samples_split=2, n_estimators=1000;, score=(train=0.998, test=0.881) total time=   8.3s\n",
      "[CV 5/5] END max_depth=10, min_samples_split=2, n_estimators=1000;, score=(train=0.999, test=0.882) total time=   9.0s\n",
      "[CV 1/5] END max_depth=10, min_samples_split=4, n_estimators=300;, score=(train=0.998, test=0.886) total time=   2.6s\n",
      "[CV 2/5] END max_depth=10, min_samples_split=4, n_estimators=300;, score=(train=0.999, test=0.883) total time=   2.5s\n",
      "[CV 3/5] END max_depth=10, min_samples_split=4, n_estimators=300;, score=(train=0.999, test=0.882) total time=   2.4s\n",
      "[CV 4/5] END max_depth=10, min_samples_split=4, n_estimators=300;, score=(train=0.998, test=0.882) total time=   2.4s\n",
      "[CV 5/5] END max_depth=10, min_samples_split=4, n_estimators=300;, score=(train=0.998, test=0.885) total time=   2.6s\n",
      "[CV 1/5] END max_depth=10, min_samples_split=4, n_estimators=500;, score=(train=0.998, test=0.885) total time=   4.2s\n",
      "[CV 2/5] END max_depth=10, min_samples_split=4, n_estimators=500;, score=(train=0.999, test=0.884) total time=   4.0s\n",
      "[CV 3/5] END max_depth=10, min_samples_split=4, n_estimators=500;, score=(train=0.998, test=0.880) total time=   3.6s\n",
      "[CV 4/5] END max_depth=10, min_samples_split=4, n_estimators=500;, score=(train=0.999, test=0.883) total time=   4.1s\n",
      "[CV 5/5] END max_depth=10, min_samples_split=4, n_estimators=500;, score=(train=0.998, test=0.887) total time=   4.0s\n",
      "[CV 1/5] END max_depth=10, min_samples_split=4, n_estimators=1000;, score=(train=0.998, test=0.886) total time=   8.7s\n",
      "[CV 2/5] END max_depth=10, min_samples_split=4, n_estimators=1000;, score=(train=0.999, test=0.882) total time=   8.5s\n",
      "[CV 3/5] END max_depth=10, min_samples_split=4, n_estimators=1000;, score=(train=0.999, test=0.881) total time=   8.9s\n",
      "[CV 4/5] END max_depth=10, min_samples_split=4, n_estimators=1000;, score=(train=0.998, test=0.884) total time=   8.5s\n",
      "[CV 5/5] END max_depth=10, min_samples_split=4, n_estimators=1000;, score=(train=0.999, test=0.885) total time=   8.9s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END max_depth=10, min_samples_split=6, n_estimators=300;, score=(train=0.998, test=0.886) total time=   2.7s\n",
      "[CV 2/5] END max_depth=10, min_samples_split=6, n_estimators=300;, score=(train=0.999, test=0.887) total time=   2.5s\n",
      "[CV 3/5] END max_depth=10, min_samples_split=6, n_estimators=300;, score=(train=0.997, test=0.884) total time=   2.4s\n",
      "[CV 4/5] END max_depth=10, min_samples_split=6, n_estimators=300;, score=(train=0.999, test=0.885) total time=   2.5s\n",
      "[CV 5/5] END max_depth=10, min_samples_split=6, n_estimators=300;, score=(train=0.998, test=0.888) total time=   2.7s\n",
      "[CV 1/5] END max_depth=10, min_samples_split=6, n_estimators=500;, score=(train=0.998, test=0.886) total time=   3.8s\n",
      "[CV 2/5] END max_depth=10, min_samples_split=6, n_estimators=500;, score=(train=0.999, test=0.886) total time=   3.6s\n",
      "[CV 3/5] END max_depth=10, min_samples_split=6, n_estimators=500;, score=(train=0.998, test=0.882) total time=58.9min\n",
      "[CV 4/5] END max_depth=10, min_samples_split=6, n_estimators=500;, score=(train=0.998, test=0.884) total time=   3.7s\n",
      "[CV 5/5] END max_depth=10, min_samples_split=6, n_estimators=500;, score=(train=0.998, test=0.887) total time=   3.9s\n",
      "[CV 1/5] END max_depth=10, min_samples_split=6, n_estimators=1000;, score=(train=0.998, test=0.887) total time=   7.6s\n",
      "[CV 2/5] END max_depth=10, min_samples_split=6, n_estimators=1000;, score=(train=0.999, test=0.887) total time=   7.9s\n",
      "[CV 3/5] END max_depth=10, min_samples_split=6, n_estimators=1000;, score=(train=0.998, test=0.882) total time=   7.4s\n",
      "[CV 4/5] END max_depth=10, min_samples_split=6, n_estimators=1000;, score=(train=0.998, test=0.887) total time=   8.2s\n",
      "[CV 5/5] END max_depth=10, min_samples_split=6, n_estimators=1000;, score=(train=0.998, test=0.886) total time=  12.3s\n",
      "[CV 1/5] END max_depth=10, min_samples_split=8, n_estimators=300;, score=(train=0.998, test=0.897) total time=   3.6s\n",
      "[CV 2/5] END max_depth=10, min_samples_split=8, n_estimators=300;, score=(train=0.998, test=0.887) total time= 5.3min\n",
      "[CV 3/5] END max_depth=10, min_samples_split=8, n_estimators=300;, score=(train=0.997, test=0.885) total time=   2.1s\n",
      "[CV 4/5] END max_depth=10, min_samples_split=8, n_estimators=300;, score=(train=0.998, test=0.891) total time=   2.0s\n",
      "[CV 5/5] END max_depth=10, min_samples_split=8, n_estimators=300;, score=(train=0.998, test=0.891) total time=   2.0s\n",
      "[CV 1/5] END max_depth=10, min_samples_split=8, n_estimators=500;, score=(train=0.998, test=0.892) total time=   3.3s\n",
      "[CV 2/5] END max_depth=10, min_samples_split=8, n_estimators=500;, score=(train=0.998, test=0.889) total time=   3.7s\n",
      "[CV 3/5] END max_depth=10, min_samples_split=8, n_estimators=500;, score=(train=0.998, test=0.886) total time=   3.5s\n",
      "[CV 4/5] END max_depth=10, min_samples_split=8, n_estimators=500;, score=(train=0.998, test=0.892) total time=12.6min\n",
      "[CV 5/5] END max_depth=10, min_samples_split=8, n_estimators=500;, score=(train=0.999, test=0.889) total time=   3.9s\n",
      "[CV 1/5] END max_depth=10, min_samples_split=8, n_estimators=1000;, score=(train=0.998, test=0.892) total time=   6.8s\n",
      "[CV 2/5] END max_depth=10, min_samples_split=8, n_estimators=1000;, score=(train=0.998, test=0.891) total time=   6.7s\n",
      "[CV 3/5] END max_depth=10, min_samples_split=8, n_estimators=1000;, score=(train=0.998, test=0.886) total time=   6.3s\n",
      "[CV 4/5] END max_depth=10, min_samples_split=8, n_estimators=1000;, score=(train=0.998, test=0.887) total time=   6.5s\n",
      "[CV 5/5] END max_depth=10, min_samples_split=8, n_estimators=1000;, score=(train=0.999, test=0.889) total time=   6.5s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=RandomForestClassifier(class_weight='balanced',\n",
       "                                              random_state=42),\n",
       "             param_grid={'max_depth': [1, 3, 5, 10],\n",
       "                         'min_samples_split': [2, 4, 6, 8],\n",
       "                         'n_estimators': [300, 500, 1000]},\n",
       "             return_train_score=True, verbose=3)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_depth': 10, 'min_samples_split': 8, 'n_estimators': 300}\n",
      "RandomForestClassifier(class_weight='balanced', max_depth=10,\n",
      "                       min_samples_split=8, n_estimators=300, random_state=42)\n"
     ]
    }
   ],
   "source": [
    "print(grid_rf.best_params_)\n",
    "print(grid_rf.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_predictions = grid_svm.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix: \n",
      " [[6938   57]\n",
      " [  74  930]] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Confusion matrix: \\n\",\n",
    "      confusion_matrix(y_train, grid_predictions), \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99      6995\n",
      "           1       0.94      0.93      0.93      1004\n",
      "\n",
      "    accuracy                           0.98      7999\n",
      "   macro avg       0.97      0.96      0.96      7999\n",
      "weighted avg       0.98      0.98      0.98      7999\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_train, grid_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_predictions = grid_svm.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix: \n",
      " [[1742   28]\n",
      " [  21  209]] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Confusion matrix: \\n\",\n",
    "      confusion_matrix(y_test, grid_predictions), \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.98      0.99      1770\n",
      "           1       0.88      0.91      0.90       230\n",
      "\n",
      "    accuracy                           0.98      2000\n",
      "   macro avg       0.93      0.95      0.94      2000\n",
      "weighted avg       0.98      0.98      0.98      2000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, grid_predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Support Vector Machine Model Cross-Validation Scores: [0.9095     0.916      0.909      0.911      0.91045523]\n",
      "Mean Cross-Validation Score: 0.9111910455227614\n",
      "\n",
      "Random Forest Model Cross-Validation Scores: [0.8765     0.8765     0.8765     0.8765     0.87693847]\n",
      "Mean Cross-Validation Score: 0.8765876938469234\n"
     ]
    }
   ],
   "source": [
    "# Cross-validation\n",
    "sv_cv_scores = cross_val_score(svm_model, X, y, cv=5)\n",
    "print(\"\\nSupport Vector Machine Model Cross-Validation Scores:\", sv_cv_scores)\n",
    "print(\"Mean Cross-Validation Score:\", sv_cv_scores.mean())\n",
    "\n",
    "rf_cv_scores = cross_val_score(rf_model, X, y, cv=5)\n",
    "print(\"\\nRandom Forest Model Cross-Validation Scores:\", rf_cv_scores)\n",
    "print(\"Mean Cross-Validation Score:\", rf_cv_scores.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random forest prediction feature_importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def important_features(original_dataframe, rf_model):\n",
    "\n",
    "    temp1 = []\n",
    "    temp2 = []\n",
    "\n",
    "    for name, score in zip(original_dataframe.columns, rf_model.best_estimator_.feature_importances_):\n",
    "        temp1.append(name)\n",
    "        temp2.append(score)\n",
    "\n",
    "    dic = {\"feature\" : temp1, \"importance\" : temp2}\n",
    "\n",
    "    feature_importance = pd.DataFrame(dic).set_index(\"feature\")\n",
    "    feature_importance.sort_values(by=\"importance\", ascending=False, inplace=True)\n",
    "\n",
    "    print(\"These are the 5 most important features: \\n\")\n",
    "    print(feature_importance[:5])\n",
    "\n",
    "    # plot features and their relative_importance\n",
    "    plt.bar(list(feature_importance.index[:5]), feature_importance[\"importance\"][:5])\n",
    "    plt.title(\"5 most important features\")\n",
    "    plt.xlabel(\"Marketing Channels\")\n",
    "    plt.ylabel(\"Relative Importance in %\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "These are the 5 most important features: \n",
      "\n",
      "             importance\n",
      "feature                \n",
      "Wordpress      0.060989\n",
      "Livejournal    0.058918\n",
      "Thisnext       0.055135\n",
      "Blogger        0.050350\n",
      "Yelp           0.046696\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "important_features(df, grid_rf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We would recommend them to use Wordpress and Livejournal."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To be cost efficent one should invest in the most efficent chanels from q3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
