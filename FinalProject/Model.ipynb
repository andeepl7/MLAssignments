{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# STEP 3 Audio Preparation and Model\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "a611495d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import librosa\n",
    "import soundfile as sf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "outputs": [],
   "source": [
    "#Global parameters\n",
    "language_dic = {\"it\" : \"Italian\", \"es\" : \"Spanish\"}\n",
    "analysis_window_length = 0.01  # 10 ms in seconds\n",
    "language_mp3_path = \"/Users/Andee/Documents/CBS - Data Science/Second Semester/Machine Learning/Assignments/MLAssignments/FinalProject/languages\""
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "outputs": [],
   "source": [
    "# number of repeats defined by minimum duration: ceil(10 seconds / min duration)\n",
    "min_clip = 1.3035\n",
    "x_seconds = 5\n",
    "num_reps = int(np.ceil(x_seconds / min_clip))\n",
    "def repeat_audio_x_seconds(track, dur, num_repeats=10, fs=16000):\n",
    "    num_samples_xs = int(fs * dur)\n",
    "    track = np.concatenate([track]*num_repeats, axis=0)\n",
    "    track = track[0:num_samples_xs]\n",
    "    return track"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "outputs": [],
   "source": [
    "data = {\"filename\": [],\"language\": [], \"tracks\": [], \"mfccs\": [] }\n",
    "language_list = os.listdir(language_mp3_path)\n",
    "\n",
    "for language in language_list:\n",
    "    language_path = os.path.join(language_mp3_path, language)\n",
    "\n",
    "    # Skip non-directory items\n",
    "    if not os.path.isdir(language_path):\n",
    "        continue\n",
    "\n",
    "    if language in language_dic:\n",
    "        language_name = language_dic[language]\n",
    "    else:\n",
    "        print(\"Unknown language!\")\n",
    "        language_name = language\n",
    "\n",
    "    clips_path = os.path.join(language_path, \"clips\")\n",
    "\n",
    "    # Check if the clips directory exists\n",
    "    if not os.path.isdir(clips_path):\n",
    "        print(f\"No 'clips' directory found in {language_path}\")\n",
    "        continue\n",
    "\n",
    "    # get a list of all files in the folder\n",
    "    mp3_list = os.listdir(clips_path)\n",
    "    mp3_list = mp3_list[:200]\n",
    "    # looping through all mp3s in one language\n",
    "    for mp3 in mp3_list:\n",
    "        # adding the filename as key\n",
    "        data[\"filename\"].append(mp3)\n",
    "        # adding the label/language\n",
    "        data[\"language\"].append(language_name)\n",
    "        # adding the clip\n",
    "        audio_path = os.path.join(clips_path, mp3)\n",
    "        audio_samples, fs = sf.read(audio_path)\n",
    "        audio_samples = repeat_audio_x_seconds(audio_samples, x_seconds, num_repeats=num_reps, fs=fs)\n",
    "        data[\"tracks\"].append(audio_samples)\n",
    "        # calculate MFCC for the clip\n",
    "        #y, sr = sf.read(audio_path)\n",
    "        y = audio_samples\n",
    "        sr = fs\n",
    "        hop_length = int(analysis_window_length * sr)\n",
    "        mfcc = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=128, hop_length=hop_length)\n",
    "        mfccs_scaled_features = np.mean(mfcc.T,axis=0)\n",
    "        data[\"mfccs\"].append(mfccs_scaled_features)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                       filename language  \\\n",
      "0  common_voice_it_35120759.mp3  Italian   \n",
      "1  common_voice_it_35392147.mp3  Italian   \n",
      "2  common_voice_it_35163674.mp3  Italian   \n",
      "3  common_voice_it_35270868.mp3  Italian   \n",
      "4  common_voice_it_35219606.mp3  Italian   \n",
      "\n",
      "                                              tracks  \\\n",
      "0  [0.0, -9.25904426914148e-13, -2.37487178360307...   \n",
      "1  [0.0, 1.898078048900853e-12, 8.351942184722794...   \n",
      "2  [0.0, 9.291632133839878e-13, 1.317183666825483...   \n",
      "3  [0.0, 3.016666777488908e-13, -5.72718142442113...   \n",
      "4  [0.0, -1.1740968440532296e-12, 4.2296575313363...   \n",
      "\n",
      "                                               mfccs  \n",
      "0  [-183.24911437422236, 128.47573750048255, -14....  \n",
      "1  [-545.4151837868718, 115.31204428122385, 13.94...  \n",
      "2  [-350.3443815564079, 132.89305024105846, 13.59...  \n",
      "3  [-431.7047493775508, 59.977884118447584, 17.76...  \n",
      "4  [-365.42030358211827, 91.3890718105903, 19.736...  \n"
     ]
    },
    {
     "data": {
      "text/plain": "(128,)"
     },
     "execution_count": 256,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(data)\n",
    "print(df.head())\n",
    "df.mfccs[50].shape"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of files loaded is: 400, in 2 languages and 400 tracks \n"
     ]
    }
   ],
   "source": [
    "#Check-point to see if all data was correctly loaded\n",
    "print(f'The number of files loaded is: {len(df[\"filename\"])}, in {df[\"language\"].nunique()} languages and {len(data[\"tracks\"])} tracks ')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(400,)\n"
     ]
    }
   ],
   "source": [
    "print(df[\"mfccs\"].shape)\n",
    "X=np.array(df['mfccs'].tolist())\n",
    "y=np.array(df['language'].tolist())"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "labelencoder=LabelEncoder()\n",
    "y=to_categorical(labelencoder.fit_transform(y))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(320, 128)\n",
      "(80, 128)\n",
      "(320, 2)\n",
      "(80, 2)\n"
     ]
    }
   ],
   "source": [
    "# using the train test split function\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y ,\n",
    "                                                    random_state=42,\n",
    "                                                    train_size=0.8)\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Model Creation"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense,Dropout,Activation,Flatten\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn import metrics"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "outputs": [],
   "source": [
    "### No of classes\n",
    "num_labels=y.shape[1]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "outputs": [],
   "source": [
    "model=Sequential()\n",
    "###first layer\n",
    "model.add(Dense(100,input_shape=(128,)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "###second layer\n",
    "model.add(Dense(200))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "###third layer\n",
    "model.add(Dense(100))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "###final layer\n",
    "model.add(Dense(num_labels))\n",
    "model.add(Activation('softmax'))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_29\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_104 (Dense)           (None, 100)               12900     \n",
      "                                                                 \n",
      " activation_104 (Activation)  (None, 100)              0         \n",
      "                                                                 \n",
      " dropout_78 (Dropout)        (None, 100)               0         \n",
      "                                                                 \n",
      " dense_105 (Dense)           (None, 200)               20200     \n",
      "                                                                 \n",
      " activation_105 (Activation)  (None, 200)              0         \n",
      "                                                                 \n",
      " dropout_79 (Dropout)        (None, 200)               0         \n",
      "                                                                 \n",
      " dense_106 (Dense)           (None, 100)               20100     \n",
      "                                                                 \n",
      " activation_106 (Activation)  (None, 100)              0         \n",
      "                                                                 \n",
      " dropout_80 (Dropout)        (None, 100)               0         \n",
      "                                                                 \n",
      " dense_107 (Dense)           (None, 2)                 202       \n",
      "                                                                 \n",
      " activation_107 (Activation)  (None, 2)                0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 53,402\n",
      "Trainable params: 53,402\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy',metrics=['accuracy'],optimizer='adam')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      " 1/10 [==>...........................] - ETA: 1:10 - loss: 28.6835 - accuracy: 0.4688\n",
      "Epoch 1: val_loss improved from inf to 8.22651, saving model to saved_models/audio_classification.hdf5\n",
      "10/10 [==============================] - 8s 55ms/step - loss: 20.8299 - accuracy: 0.5312 - val_loss: 8.2265 - val_accuracy: 0.4500\n",
      "Epoch 2/100\n",
      " 6/10 [=================>............] - ETA: 0s - loss: 15.2666 - accuracy: 0.5000\n",
      "Epoch 2: val_loss improved from 8.22651 to 2.57317, saving model to saved_models/audio_classification.hdf5\n",
      "10/10 [==============================] - 0s 36ms/step - loss: 15.1961 - accuracy: 0.4719 - val_loss: 2.5732 - val_accuracy: 0.5500\n",
      "Epoch 3/100\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 13.7121 - accuracy: 0.5000\n",
      "Epoch 3: val_loss improved from 2.57317 to 0.85716, saving model to saved_models/audio_classification.hdf5\n",
      "10/10 [==============================] - 0s 22ms/step - loss: 10.4543 - accuracy: 0.5156 - val_loss: 0.8572 - val_accuracy: 0.5750\n",
      "Epoch 4/100\n",
      " 7/10 [====================>.........] - ETA: 0s - loss: 9.1425 - accuracy: 0.5446 \n",
      "Epoch 4: val_loss improved from 0.85716 to 0.55576, saving model to saved_models/audio_classification.hdf5\n",
      "10/10 [==============================] - 0s 44ms/step - loss: 8.6254 - accuracy: 0.5406 - val_loss: 0.5558 - val_accuracy: 0.7250\n",
      "Epoch 5/100\n",
      " 8/10 [=======================>......] - ETA: 0s - loss: 5.6540 - accuracy: 0.5547\n",
      "Epoch 5: val_loss improved from 0.55576 to 0.46197, saving model to saved_models/audio_classification.hdf5\n",
      "10/10 [==============================] - 0s 47ms/step - loss: 5.8168 - accuracy: 0.5375 - val_loss: 0.4620 - val_accuracy: 0.7750\n",
      "Epoch 6/100\n",
      " 7/10 [====================>.........] - ETA: 0s - loss: 5.1705 - accuracy: 0.5491\n",
      "Epoch 6: val_loss did not improve from 0.46197\n",
      "10/10 [==============================] - 0s 22ms/step - loss: 4.7223 - accuracy: 0.5781 - val_loss: 0.7088 - val_accuracy: 0.5875\n",
      "Epoch 7/100\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 4.2132 - accuracy: 0.5833\n",
      "Epoch 7: val_loss did not improve from 0.46197\n",
      "10/10 [==============================] - 0s 21ms/step - loss: 4.1600 - accuracy: 0.5875 - val_loss: 0.7994 - val_accuracy: 0.4875\n",
      "Epoch 8/100\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 3.6712 - accuracy: 0.5833\n",
      "Epoch 8: val_loss did not improve from 0.46197\n",
      "10/10 [==============================] - 0s 20ms/step - loss: 3.6503 - accuracy: 0.5750 - val_loss: 0.7290 - val_accuracy: 0.4875\n",
      "Epoch 9/100\n",
      " 7/10 [====================>.........] - ETA: 0s - loss: 2.8845 - accuracy: 0.5938\n",
      "Epoch 9: val_loss did not improve from 0.46197\n",
      "10/10 [==============================] - 0s 25ms/step - loss: 2.7104 - accuracy: 0.5938 - val_loss: 0.6483 - val_accuracy: 0.5625\n",
      "Epoch 10/100\n",
      " 8/10 [=======================>......] - ETA: 0s - loss: 2.7980 - accuracy: 0.5703\n",
      "Epoch 10: val_loss did not improve from 0.46197\n",
      "10/10 [==============================] - 0s 24ms/step - loss: 2.6220 - accuracy: 0.5719 - val_loss: 0.5247 - val_accuracy: 0.7875\n",
      "Epoch 11/100\n",
      "10/10 [==============================] - ETA: 0s - loss: 2.4748 - accuracy: 0.6062\n",
      "Epoch 11: val_loss did not improve from 0.46197\n",
      "10/10 [==============================] - 0s 22ms/step - loss: 2.4748 - accuracy: 0.6062 - val_loss: 0.5357 - val_accuracy: 0.7500\n",
      "Epoch 12/100\n",
      " 5/10 [==============>...............] - ETA: 0s - loss: 1.8156 - accuracy: 0.6500\n",
      "Epoch 12: val_loss did not improve from 0.46197\n",
      "10/10 [==============================] - 0s 22ms/step - loss: 1.9764 - accuracy: 0.6687 - val_loss: 0.5056 - val_accuracy: 0.8375\n",
      "Epoch 13/100\n",
      "10/10 [==============================] - ETA: 0s - loss: 2.0405 - accuracy: 0.6375\n",
      "Epoch 13: val_loss did not improve from 0.46197\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 2.0405 - accuracy: 0.6375 - val_loss: 0.4778 - val_accuracy: 0.8625\n",
      "Epoch 14/100\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 1.7184 - accuracy: 0.6076\n",
      "Epoch 14: val_loss improved from 0.46197 to 0.44718, saving model to saved_models/audio_classification.hdf5\n",
      "10/10 [==============================] - 0s 26ms/step - loss: 1.6360 - accuracy: 0.6250 - val_loss: 0.4472 - val_accuracy: 0.8375\n",
      "Epoch 15/100\n",
      " 7/10 [====================>.........] - ETA: 0s - loss: 1.6235 - accuracy: 0.5982\n",
      "Epoch 15: val_loss did not improve from 0.44718\n",
      "10/10 [==============================] - 0s 22ms/step - loss: 1.5366 - accuracy: 0.6313 - val_loss: 0.4522 - val_accuracy: 0.8250\n",
      "Epoch 16/100\n",
      " 6/10 [=================>............] - ETA: 0s - loss: 1.6156 - accuracy: 0.6562\n",
      "Epoch 16: val_loss did not improve from 0.44718\n",
      "10/10 [==============================] - 0s 20ms/step - loss: 1.5755 - accuracy: 0.6438 - val_loss: 0.4615 - val_accuracy: 0.8000\n",
      "Epoch 17/100\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 1.5221 - accuracy: 0.6458\n",
      "Epoch 17: val_loss did not improve from 0.44718\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 1.4248 - accuracy: 0.6625 - val_loss: 0.4660 - val_accuracy: 0.7750\n",
      "Epoch 18/100\n",
      "10/10 [==============================] - ETA: 0s - loss: 1.2971 - accuracy: 0.6781\n",
      "Epoch 18: val_loss improved from 0.44718 to 0.44350, saving model to saved_models/audio_classification.hdf5\n",
      "10/10 [==============================] - 0s 26ms/step - loss: 1.2971 - accuracy: 0.6781 - val_loss: 0.4435 - val_accuracy: 0.8000\n",
      "Epoch 19/100\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 1.1321 - accuracy: 0.6736\n",
      "Epoch 19: val_loss improved from 0.44350 to 0.44004, saving model to saved_models/audio_classification.hdf5\n",
      "10/10 [==============================] - 0s 25ms/step - loss: 1.1278 - accuracy: 0.6750 - val_loss: 0.4400 - val_accuracy: 0.8375\n",
      "Epoch 20/100\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.9304 - accuracy: 0.6719\n",
      "Epoch 20: val_loss did not improve from 0.44004\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.9304 - accuracy: 0.6719 - val_loss: 0.4430 - val_accuracy: 0.8125\n",
      "Epoch 21/100\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.9063 - accuracy: 0.7292\n",
      "Epoch 21: val_loss improved from 0.44004 to 0.43777, saving model to saved_models/audio_classification.hdf5\n",
      "10/10 [==============================] - 0s 26ms/step - loss: 0.9686 - accuracy: 0.7156 - val_loss: 0.4378 - val_accuracy: 0.7875\n",
      "Epoch 22/100\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.9548 - accuracy: 0.6844\n",
      "Epoch 22: val_loss did not improve from 0.43777\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.9548 - accuracy: 0.6844 - val_loss: 0.4403 - val_accuracy: 0.7875\n",
      "Epoch 23/100\n",
      " 6/10 [=================>............] - ETA: 0s - loss: 0.8468 - accuracy: 0.7031\n",
      "Epoch 23: val_loss did not improve from 0.43777\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 0.8580 - accuracy: 0.7188 - val_loss: 0.4519 - val_accuracy: 0.7750\n",
      "Epoch 24/100\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.7528 - accuracy: 0.7292\n",
      "Epoch 24: val_loss did not improve from 0.43777\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.7766 - accuracy: 0.7281 - val_loss: 0.4557 - val_accuracy: 0.7750\n",
      "Epoch 25/100\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.8071 - accuracy: 0.6979\n",
      "Epoch 25: val_loss did not improve from 0.43777\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 0.7857 - accuracy: 0.7063 - val_loss: 0.4449 - val_accuracy: 0.7875\n",
      "Epoch 26/100\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.6770 - accuracy: 0.7292\n",
      "Epoch 26: val_loss did not improve from 0.43777\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.7050 - accuracy: 0.7219 - val_loss: 0.4411 - val_accuracy: 0.7875\n",
      "Epoch 27/100\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.7097 - accuracy: 0.7326\n",
      "Epoch 27: val_loss did not improve from 0.43777\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.6881 - accuracy: 0.7312 - val_loss: 0.4447 - val_accuracy: 0.7750\n",
      "Epoch 28/100\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.6690 - accuracy: 0.7326\n",
      "Epoch 28: val_loss did not improve from 0.43777\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.6493 - accuracy: 0.7375 - val_loss: 0.4463 - val_accuracy: 0.7750\n",
      "Epoch 29/100\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.6444 - accuracy: 0.8125\n",
      "Epoch 29: val_loss improved from 0.43777 to 0.43346, saving model to saved_models/audio_classification.hdf5\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.5998 - accuracy: 0.7656 - val_loss: 0.4335 - val_accuracy: 0.7875\n",
      "Epoch 30/100\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.5612 - accuracy: 0.7188\n",
      "Epoch 30: val_loss improved from 0.43346 to 0.42454, saving model to saved_models/audio_classification.hdf5\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.6504 - accuracy: 0.7688 - val_loss: 0.4245 - val_accuracy: 0.7875\n",
      "Epoch 31/100\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.2463 - accuracy: 0.8750\n",
      "Epoch 31: val_loss improved from 0.42454 to 0.41845, saving model to saved_models/audio_classification.hdf5\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.5497 - accuracy: 0.8031 - val_loss: 0.4185 - val_accuracy: 0.7875\n",
      "Epoch 32/100\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.4103 - accuracy: 0.5938\n",
      "Epoch 32: val_loss improved from 0.41845 to 0.41620, saving model to saved_models/audio_classification.hdf5\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.6752 - accuracy: 0.7500 - val_loss: 0.4162 - val_accuracy: 0.8000\n",
      "Epoch 33/100\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.6316 - accuracy: 0.8125\n",
      "Epoch 33: val_loss improved from 0.41620 to 0.41304, saving model to saved_models/audio_classification.hdf5\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.6188 - accuracy: 0.7719 - val_loss: 0.4130 - val_accuracy: 0.8000\n",
      "Epoch 34/100\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.5434 - accuracy: 0.7188\n",
      "Epoch 34: val_loss improved from 0.41304 to 0.40558, saving model to saved_models/audio_classification.hdf5\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.5403 - accuracy: 0.7531 - val_loss: 0.4056 - val_accuracy: 0.8000\n",
      "Epoch 35/100\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.8044 - accuracy: 0.5938\n",
      "Epoch 35: val_loss improved from 0.40558 to 0.39720, saving model to saved_models/audio_classification.hdf5\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.5797 - accuracy: 0.7719 - val_loss: 0.3972 - val_accuracy: 0.8125\n",
      "Epoch 36/100\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.6100 - accuracy: 0.7812\n",
      "Epoch 36: val_loss did not improve from 0.39720\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.5618 - accuracy: 0.7688 - val_loss: 0.3994 - val_accuracy: 0.8500\n",
      "Epoch 37/100\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.6279 - accuracy: 0.7812\n",
      "Epoch 37: val_loss improved from 0.39720 to 0.38846, saving model to saved_models/audio_classification.hdf5\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.5314 - accuracy: 0.7875 - val_loss: 0.3885 - val_accuracy: 0.8500\n",
      "Epoch 38/100\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.8255 - accuracy: 0.5938\n",
      "Epoch 38: val_loss improved from 0.38846 to 0.38602, saving model to saved_models/audio_classification.hdf5\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.5045 - accuracy: 0.7875 - val_loss: 0.3860 - val_accuracy: 0.8625\n",
      "Epoch 39/100\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.2986 - accuracy: 0.9062\n",
      "Epoch 39: val_loss improved from 0.38602 to 0.38237, saving model to saved_models/audio_classification.hdf5\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.5369 - accuracy: 0.7906 - val_loss: 0.3824 - val_accuracy: 0.8500\n",
      "Epoch 40/100\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.3039 - accuracy: 0.8750\n",
      "Epoch 40: val_loss improved from 0.38237 to 0.37521, saving model to saved_models/audio_classification.hdf5\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4814 - accuracy: 0.7875 - val_loss: 0.3752 - val_accuracy: 0.8250\n",
      "Epoch 41/100\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.3208 - accuracy: 0.9062\n",
      "Epoch 41: val_loss improved from 0.37521 to 0.37133, saving model to saved_models/audio_classification.hdf5\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.4561 - accuracy: 0.8125 - val_loss: 0.3713 - val_accuracy: 0.8250\n",
      "Epoch 42/100\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.9232 - accuracy: 0.7188\n",
      "Epoch 42: val_loss improved from 0.37133 to 0.35813, saving model to saved_models/audio_classification.hdf5\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.5128 - accuracy: 0.7844 - val_loss: 0.3581 - val_accuracy: 0.8500\n",
      "Epoch 43/100\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.3410 - accuracy: 0.7812\n",
      "Epoch 43: val_loss improved from 0.35813 to 0.35558, saving model to saved_models/audio_classification.hdf5\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.5246 - accuracy: 0.7750 - val_loss: 0.3556 - val_accuracy: 0.8500\n",
      "Epoch 44/100\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.5258 - accuracy: 0.7812\n",
      "Epoch 44: val_loss improved from 0.35558 to 0.35442, saving model to saved_models/audio_classification.hdf5\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.4299 - accuracy: 0.8062 - val_loss: 0.3544 - val_accuracy: 0.8375\n",
      "Epoch 45/100\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.3262 - accuracy: 0.8125\n",
      "Epoch 45: val_loss improved from 0.35442 to 0.35363, saving model to saved_models/audio_classification.hdf5\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.4942 - accuracy: 0.7875 - val_loss: 0.3536 - val_accuracy: 0.8375\n",
      "Epoch 46/100\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.4831 - accuracy: 0.7812\n",
      "Epoch 46: val_loss improved from 0.35363 to 0.35256, saving model to saved_models/audio_classification.hdf5\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4826 - accuracy: 0.8031 - val_loss: 0.3526 - val_accuracy: 0.8500\n",
      "Epoch 47/100\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.6926 - accuracy: 0.7812\n",
      "Epoch 47: val_loss improved from 0.35256 to 0.34486, saving model to saved_models/audio_classification.hdf5\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.4248 - accuracy: 0.8125 - val_loss: 0.3449 - val_accuracy: 0.8375\n",
      "Epoch 48/100\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.4094 - accuracy: 0.7812\n",
      "Epoch 48: val_loss improved from 0.34486 to 0.33437, saving model to saved_models/audio_classification.hdf5\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.4253 - accuracy: 0.8250 - val_loss: 0.3344 - val_accuracy: 0.8375\n",
      "Epoch 49/100\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.4429 - accuracy: 0.7812\n",
      "Epoch 49: val_loss improved from 0.33437 to 0.32235, saving model to saved_models/audio_classification.hdf5\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.3682 - accuracy: 0.8562 - val_loss: 0.3224 - val_accuracy: 0.8500\n",
      "Epoch 50/100\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.3904 - accuracy: 0.8472\n",
      "Epoch 50: val_loss improved from 0.32235 to 0.32085, saving model to saved_models/audio_classification.hdf5\n",
      "10/10 [==============================] - 0s 20ms/step - loss: 0.3873 - accuracy: 0.8469 - val_loss: 0.3208 - val_accuracy: 0.8625\n",
      "Epoch 51/100\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.3918 - accuracy: 0.8368\n",
      "Epoch 51: val_loss did not improve from 0.32085\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.3793 - accuracy: 0.8375 - val_loss: 0.3215 - val_accuracy: 0.8625\n",
      "Epoch 52/100\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.9518 - accuracy: 0.6562\n",
      "Epoch 52: val_loss did not improve from 0.32085\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.4188 - accuracy: 0.8406 - val_loss: 0.3287 - val_accuracy: 0.8750\n",
      "Epoch 53/100\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.3810 - accuracy: 0.8194\n",
      "Epoch 53: val_loss did not improve from 0.32085\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.3640 - accuracy: 0.8281 - val_loss: 0.3221 - val_accuracy: 0.8625\n",
      "Epoch 54/100\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.4376 - accuracy: 0.7906\n",
      "Epoch 54: val_loss improved from 0.32085 to 0.31114, saving model to saved_models/audio_classification.hdf5\n",
      "10/10 [==============================] - 0s 20ms/step - loss: 0.4376 - accuracy: 0.7906 - val_loss: 0.3111 - val_accuracy: 0.8750\n",
      "Epoch 55/100\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.3406 - accuracy: 0.8438\n",
      "Epoch 55: val_loss improved from 0.31114 to 0.30392, saving model to saved_models/audio_classification.hdf5\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.3611 - accuracy: 0.8406 - val_loss: 0.3039 - val_accuracy: 0.8625\n",
      "Epoch 56/100\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.3671 - accuracy: 0.8375\n",
      "Epoch 56: val_loss improved from 0.30392 to 0.29643, saving model to saved_models/audio_classification.hdf5\n",
      "10/10 [==============================] - 0s 21ms/step - loss: 0.3671 - accuracy: 0.8375 - val_loss: 0.2964 - val_accuracy: 0.8500\n",
      "Epoch 57/100\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.2490 - accuracy: 0.8750\n",
      "Epoch 57: val_loss improved from 0.29643 to 0.28916, saving model to saved_models/audio_classification.hdf5\n",
      "10/10 [==============================] - 0s 19ms/step - loss: 0.3225 - accuracy: 0.8594 - val_loss: 0.2892 - val_accuracy: 0.8625\n",
      "Epoch 58/100\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.3307 - accuracy: 0.8656\n",
      "Epoch 58: val_loss improved from 0.28916 to 0.27889, saving model to saved_models/audio_classification.hdf5\n",
      "10/10 [==============================] - 0s 28ms/step - loss: 0.3307 - accuracy: 0.8656 - val_loss: 0.2789 - val_accuracy: 0.8500\n",
      "Epoch 59/100\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.2320 - accuracy: 0.9062\n",
      "Epoch 59: val_loss improved from 0.27889 to 0.26677, saving model to saved_models/audio_classification.hdf5\n",
      "10/10 [==============================] - 0s 44ms/step - loss: 0.3116 - accuracy: 0.8656 - val_loss: 0.2668 - val_accuracy: 0.8625\n",
      "Epoch 60/100\n",
      " 6/10 [=================>............] - ETA: 0s - loss: 0.2900 - accuracy: 0.8802\n",
      "Epoch 60: val_loss improved from 0.26677 to 0.26640, saving model to saved_models/audio_classification.hdf5\n",
      "10/10 [==============================] - 0s 37ms/step - loss: 0.2941 - accuracy: 0.8781 - val_loss: 0.2664 - val_accuracy: 0.8500\n",
      "Epoch 61/100\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.3157 - accuracy: 0.8750\n",
      "Epoch 61: val_loss improved from 0.26640 to 0.26235, saving model to saved_models/audio_classification.hdf5\n",
      "10/10 [==============================] - 0s 32ms/step - loss: 0.3351 - accuracy: 0.8594 - val_loss: 0.2623 - val_accuracy: 0.8875\n",
      "Epoch 62/100\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.3235 - accuracy: 0.8594\n",
      "Epoch 62: val_loss did not improve from 0.26235\n",
      "10/10 [==============================] - 0s 24ms/step - loss: 0.3235 - accuracy: 0.8594 - val_loss: 0.2681 - val_accuracy: 0.8625\n",
      "Epoch 63/100\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.3189 - accuracy: 0.8562\n",
      "Epoch 63: val_loss did not improve from 0.26235\n",
      "10/10 [==============================] - 0s 20ms/step - loss: 0.3189 - accuracy: 0.8562 - val_loss: 0.2654 - val_accuracy: 0.8500\n",
      "Epoch 64/100\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.3344 - accuracy: 0.8646\n",
      "Epoch 64: val_loss improved from 0.26235 to 0.25689, saving model to saved_models/audio_classification.hdf5\n",
      "10/10 [==============================] - 0s 32ms/step - loss: 0.3493 - accuracy: 0.8562 - val_loss: 0.2569 - val_accuracy: 0.8625\n",
      "Epoch 65/100\n",
      " 7/10 [====================>.........] - ETA: 0s - loss: 0.3276 - accuracy: 0.8661\n",
      "Epoch 65: val_loss did not improve from 0.25689\n",
      "10/10 [==============================] - 0s 30ms/step - loss: 0.3116 - accuracy: 0.8656 - val_loss: 0.2629 - val_accuracy: 0.8625\n",
      "Epoch 66/100\n",
      " 8/10 [=======================>......] - ETA: 0s - loss: 0.3488 - accuracy: 0.8633\n",
      "Epoch 66: val_loss improved from 0.25689 to 0.25472, saving model to saved_models/audio_classification.hdf5\n",
      "10/10 [==============================] - 0s 33ms/step - loss: 0.3291 - accuracy: 0.8781 - val_loss: 0.2547 - val_accuracy: 0.8750\n",
      "Epoch 67/100\n",
      " 8/10 [=======================>......] - ETA: 0s - loss: 0.2564 - accuracy: 0.8984\n",
      "Epoch 67: val_loss improved from 0.25472 to 0.24305, saving model to saved_models/audio_classification.hdf5\n",
      "10/10 [==============================] - 0s 37ms/step - loss: 0.2384 - accuracy: 0.9156 - val_loss: 0.2430 - val_accuracy: 0.8875\n",
      "Epoch 68/100\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.2991 - accuracy: 0.8542\n",
      "Epoch 68: val_loss improved from 0.24305 to 0.23516, saving model to saved_models/audio_classification.hdf5\n",
      "10/10 [==============================] - 0s 30ms/step - loss: 0.3194 - accuracy: 0.8500 - val_loss: 0.2352 - val_accuracy: 0.8750\n",
      "Epoch 69/100\n",
      " 7/10 [====================>.........] - ETA: 0s - loss: 0.3108 - accuracy: 0.8616\n",
      "Epoch 69: val_loss did not improve from 0.23516\n",
      "10/10 [==============================] - 0s 26ms/step - loss: 0.3077 - accuracy: 0.8625 - val_loss: 0.2434 - val_accuracy: 0.8875\n",
      "Epoch 70/100\n",
      " 6/10 [=================>............] - ETA: 0s - loss: 0.2418 - accuracy: 0.8906\n",
      "Epoch 70: val_loss did not improve from 0.23516\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 0.2431 - accuracy: 0.8938 - val_loss: 0.2363 - val_accuracy: 0.9000\n",
      "Epoch 71/100\n",
      " 5/10 [==============>...............] - ETA: 0s - loss: 0.2472 - accuracy: 0.9000\n",
      "Epoch 71: val_loss improved from 0.23516 to 0.22670, saving model to saved_models/audio_classification.hdf5\n",
      "10/10 [==============================] - 0s 33ms/step - loss: 0.2735 - accuracy: 0.8719 - val_loss: 0.2267 - val_accuracy: 0.9000\n",
      "Epoch 72/100\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.2907 - accuracy: 0.8719\n",
      "Epoch 72: val_loss improved from 0.22670 to 0.22438, saving model to saved_models/audio_classification.hdf5\n",
      "10/10 [==============================] - 0s 28ms/step - loss: 0.2907 - accuracy: 0.8719 - val_loss: 0.2244 - val_accuracy: 0.8875\n",
      "Epoch 73/100\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.2597 - accuracy: 0.8938\n",
      "Epoch 73: val_loss did not improve from 0.22438\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.2597 - accuracy: 0.8938 - val_loss: 0.2288 - val_accuracy: 0.8875\n",
      "Epoch 74/100\n",
      " 5/10 [==============>...............] - ETA: 0s - loss: 0.2301 - accuracy: 0.9062\n",
      "Epoch 74: val_loss improved from 0.22438 to 0.22390, saving model to saved_models/audio_classification.hdf5\n",
      "10/10 [==============================] - 0s 32ms/step - loss: 0.2818 - accuracy: 0.8719 - val_loss: 0.2239 - val_accuracy: 0.8875\n",
      "Epoch 75/100\n",
      " 8/10 [=======================>......] - ETA: 0s - loss: 0.2574 - accuracy: 0.8828\n",
      "Epoch 75: val_loss did not improve from 0.22390\n",
      "10/10 [==============================] - 0s 25ms/step - loss: 0.2554 - accuracy: 0.8906 - val_loss: 0.2277 - val_accuracy: 0.9000\n",
      "Epoch 76/100\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.1389 - accuracy: 0.9375\n",
      "Epoch 76: val_loss did not improve from 0.22390\n",
      "10/10 [==============================] - 0s 27ms/step - loss: 0.2700 - accuracy: 0.8781 - val_loss: 0.2298 - val_accuracy: 0.9000\n",
      "Epoch 77/100\n",
      " 8/10 [=======================>......] - ETA: 0s - loss: 0.2325 - accuracy: 0.8867\n",
      "Epoch 77: val_loss improved from 0.22390 to 0.22315, saving model to saved_models/audio_classification.hdf5\n",
      "10/10 [==============================] - 0s 47ms/step - loss: 0.2262 - accuracy: 0.8938 - val_loss: 0.2231 - val_accuracy: 0.8875\n",
      "Epoch 78/100\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.2549 - accuracy: 0.9031\n",
      "Epoch 78: val_loss improved from 0.22315 to 0.21319, saving model to saved_models/audio_classification.hdf5\n",
      "10/10 [==============================] - 0s 27ms/step - loss: 0.2549 - accuracy: 0.9031 - val_loss: 0.2132 - val_accuracy: 0.9000\n",
      "Epoch 79/100\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.2661 - accuracy: 0.8854\n",
      "Epoch 79: val_loss improved from 0.21319 to 0.20524, saving model to saved_models/audio_classification.hdf5\n",
      "10/10 [==============================] - 0s 30ms/step - loss: 0.2504 - accuracy: 0.8938 - val_loss: 0.2052 - val_accuracy: 0.9250\n",
      "Epoch 80/100\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.3136 - accuracy: 0.8750\n",
      "Epoch 80: val_loss improved from 0.20524 to 0.20414, saving model to saved_models/audio_classification.hdf5\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.2290 - accuracy: 0.8969 - val_loss: 0.2041 - val_accuracy: 0.9125\n",
      "Epoch 81/100\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.2186 - accuracy: 0.8750\n",
      "Epoch 81: val_loss did not improve from 0.20414\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.2779 - accuracy: 0.8719 - val_loss: 0.2051 - val_accuracy: 0.9125\n",
      "Epoch 82/100\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.2031 - accuracy: 0.8750\n",
      "Epoch 82: val_loss did not improve from 0.20414\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.2025 - accuracy: 0.9125 - val_loss: 0.2075 - val_accuracy: 0.9125\n",
      "Epoch 83/100\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.1604 - accuracy: 0.9375\n",
      "Epoch 83: val_loss did not improve from 0.20414\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.2402 - accuracy: 0.9031 - val_loss: 0.2052 - val_accuracy: 0.9125\n",
      "Epoch 84/100\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.3172 - accuracy: 0.8438\n",
      "Epoch 84: val_loss improved from 0.20414 to 0.19874, saving model to saved_models/audio_classification.hdf5\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.2058 - accuracy: 0.9125 - val_loss: 0.1987 - val_accuracy: 0.9250\n",
      "Epoch 85/100\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.1504 - accuracy: 0.9375\n",
      "Epoch 85: val_loss improved from 0.19874 to 0.18984, saving model to saved_models/audio_classification.hdf5\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.2332 - accuracy: 0.8938 - val_loss: 0.1898 - val_accuracy: 0.9250\n",
      "Epoch 86/100\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.2190 - accuracy: 0.8750\n",
      "Epoch 86: val_loss improved from 0.18984 to 0.18495, saving model to saved_models/audio_classification.hdf5\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.1955 - accuracy: 0.9219 - val_loss: 0.1850 - val_accuracy: 0.9375\n",
      "Epoch 87/100\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.2485 - accuracy: 0.9062\n",
      "Epoch 87: val_loss did not improve from 0.18495\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.2375 - accuracy: 0.9000 - val_loss: 0.1891 - val_accuracy: 0.9375\n",
      "Epoch 88/100\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.2981 - accuracy: 0.8750\n",
      "Epoch 88: val_loss did not improve from 0.18495\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.2188 - accuracy: 0.8969 - val_loss: 0.1951 - val_accuracy: 0.9250\n",
      "Epoch 89/100\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.1789 - accuracy: 0.9375\n",
      "Epoch 89: val_loss did not improve from 0.18495\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.1807 - accuracy: 0.9156 - val_loss: 0.1898 - val_accuracy: 0.9375\n",
      "Epoch 90/100\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.1283 - accuracy: 0.9375\n",
      "Epoch 90: val_loss did not improve from 0.18495\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.2427 - accuracy: 0.8969 - val_loss: 0.1902 - val_accuracy: 0.9250\n",
      "Epoch 91/100\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.1069 - accuracy: 0.9688\n",
      "Epoch 91: val_loss did not improve from 0.18495\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.2087 - accuracy: 0.9031 - val_loss: 0.1953 - val_accuracy: 0.9125\n",
      "Epoch 92/100\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.3520 - accuracy: 0.8750\n",
      "Epoch 92: val_loss did not improve from 0.18495\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.2438 - accuracy: 0.9000 - val_loss: 0.1901 - val_accuracy: 0.9250\n",
      "Epoch 93/100\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.2282 - accuracy: 0.8750\n",
      "Epoch 93: val_loss improved from 0.18495 to 0.18477, saving model to saved_models/audio_classification.hdf5\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.2289 - accuracy: 0.9219 - val_loss: 0.1848 - val_accuracy: 0.9250\n",
      "Epoch 94/100\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.1081 - accuracy: 0.9375\n",
      "Epoch 94: val_loss did not improve from 0.18477\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.1944 - accuracy: 0.9094 - val_loss: 0.1899 - val_accuracy: 0.9250\n",
      "Epoch 95/100\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.1171 - accuracy: 0.9688\n",
      "Epoch 95: val_loss did not improve from 0.18477\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.2046 - accuracy: 0.9187 - val_loss: 0.1961 - val_accuracy: 0.9250\n",
      "Epoch 96/100\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.0725 - accuracy: 0.9688\n",
      "Epoch 96: val_loss did not improve from 0.18477\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.2046 - accuracy: 0.8906 - val_loss: 0.1948 - val_accuracy: 0.9250\n",
      "Epoch 97/100\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.0856 - accuracy: 0.9688\n",
      "Epoch 97: val_loss did not improve from 0.18477\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.1865 - accuracy: 0.9187 - val_loss: 0.1884 - val_accuracy: 0.9000\n",
      "Epoch 98/100\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.0555 - accuracy: 1.0000\n",
      "Epoch 98: val_loss improved from 0.18477 to 0.17944, saving model to saved_models/audio_classification.hdf5\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.1904 - accuracy: 0.9125 - val_loss: 0.1794 - val_accuracy: 0.9125\n",
      "Epoch 99/100\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.1396 - accuracy: 0.9375\n",
      "Epoch 99: val_loss did not improve from 0.17944\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.1698 - accuracy: 0.9344 - val_loss: 0.1797 - val_accuracy: 0.9250\n",
      "Epoch 100/100\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.2528 - accuracy: 0.8750\n",
      "Epoch 100: val_loss improved from 0.17944 to 0.17598, saving model to saved_models/audio_classification.hdf5\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.1654 - accuracy: 0.9344 - val_loss: 0.1760 - val_accuracy: 0.9125\n",
      "Training completed in time:  0:00:28.612656\n"
     ]
    }
   ],
   "source": [
    "## Training model\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from datetime import datetime\n",
    "\n",
    "num_epochs = 100\n",
    "num_batch_size = 32\n",
    "\n",
    "checkpointer = ModelCheckpoint(filepath='saved_models/audio_classification.hdf5',\n",
    "                               verbose=1, save_best_only=True)\n",
    "start = datetime.now()\n",
    "\n",
    "model.fit(X_train, y_train, batch_size=num_batch_size, epochs=num_epochs, validation_data=(X_test, y_test), callbacks=[checkpointer], verbose=1)\n",
    "\n",
    "\n",
    "duration = datetime.now() - start\n",
    "print(\"Training completed in time: \", duration)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9125000238418579\n"
     ]
    }
   ],
   "source": [
    "test_accuracy=model.evaluate(X_test,y_test,verbose=0)\n",
    "print(test_accuracy[1])"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
